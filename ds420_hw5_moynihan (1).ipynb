{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DS420: Homework 5 Spark Streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this homework, your goal to setup an end-to-end data streaming application to collect data from Twitter and analyze the data with Spark Streaming and Spark SQL. \n",
    "\n",
    "Firstly, we need to setup a Developer API acocunt with Twitter and create an application to get credentials. \n",
    "    \n",
    "Once you have that you then need to complete the `hw5_twitterKafkaProducer.py` program in order to setup the twitter stream producer. You can verify whether the producer is up running by starting a kafka-console-consumer on the side to monitor. \n",
    "\n",
    "Lastly, you need to finish this notebook to setup a Spark Streaming consumer, analyze the stream in real-time, and finally visualize some of the tweeter stream activities with Pandas. Keep your producer running while working on this notebook. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Create a Spark session, and named it as `hw5_xxx`, where `xxx` is your last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just change the appName but don't modify the configurations!\n",
    "\n",
    "spark = SparkSession.builder.appName('hw5_moynihan')          \\\n",
    "                    .config('spark.jars.packages','org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1')\\\n",
    "                    .config('spark.jars.packages','org.apache.kafka:kafka-clients:2.4.1')\\\n",
    "                    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from kafka into a streaming DataFrame\n",
    "# Ensure to supply the bootstrap server and the channel;\n",
    "# and include the timestamp as you read it. \n",
    "\n",
    "streaming = spark.readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"ds420-moynihan\") \\\n",
    "  .option('includeTimestamp','True')\\\n",
    "  .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only timestamp and value columns. Cast value column into String type.\n",
    "streaming = streaming.selectExpr( \"CAST(value AS STRING)\", 'timestamp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Run a simple query to show the raw data of the `value` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the `value` column only from the streaming DataFrame into rawValue\n",
    "rawValue = streaming.select('value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a streaming query with rawValue\n",
    "\n",
    "valueQuery = (rawValue.writeStream\n",
    "             .format('memory')\n",
    "             .queryName('valueQuery')\n",
    "             .start())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566894...|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566894...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566892...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566893...|\n",
      "|{\"id\": \"132566894...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Poll the results every 5 seconds and show the first ten records\n",
    "# Run this for 5 iterations. \n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "for x in range(10):\n",
    "    df = spark.sql('SELECT * FROM valueQuery')\n",
    "    df.show(10)\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the query once it's done. \n",
    "\n",
    "valueQuery.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Create schema for the raw data with the hint from the printed results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create the dataSchema with StructType()\n",
    "\n",
    "dataSchema = dataSchema = StructType([ \\\n",
    "    StructField(\"id\",StringType(),True), \\\n",
    "    StructField(\"user\",StringType(),True), \\\n",
    "    StructField(\"follower\",IntegerType(),True), \\\n",
    "    StructField(\"friends\", IntegerType(), True), \\\n",
    "    StructField(\"tweet\", StringType(), True), \\\n",
    "    StructField(\"hashtag\", IntegerType(), True), \\\n",
    "    StructField(\"ts\", TimestampType(),True), \\\n",
    "    StructField(\"retweet\",IntegerType(),True), \\\n",
    "    StructField(\"favorite\",IntegerType(),True) \\\n",
    " \n",
    "  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,StringType,true),StructField(user,StringType,true),StructField(follower,IntegerType,true),StructField(friends,IntegerType,true),StructField(tweet,StringType,true),StructField(hashtag,StringType,true),StructField(ts,TimestampType,true),StructField(retweet,IntegerType,true),StructField(favorite,IntegerType,true)))\n"
     ]
    }
   ],
   "source": [
    "# Show the schema, use this as the hint to finish the question above\n",
    "\n",
    "print(dataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new column for the `streaming` DataFrame named as `json`. Use `from_json` function to parse the string in `value` column into `json` column. Save the resulting DataFrame into `df`.\n",
    "`from_json` docs: [link](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = streaming.withColumn('json', from_json('value', dataSchema))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- json: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |    |-- follower: integer (nullable = true)\n",
      " |    |-- friends: integer (nullable = true)\n",
      " |    |-- tweet: string (nullable = true)\n",
      " |    |-- hashtag: string (nullable = true)\n",
      " |    |-- ts: timestamp (nullable = true)\n",
      " |    |-- retweet: integer (nullable = true)\n",
      " |    |-- favorite: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checkout the schema of df. \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Generate new columns with the sub-fields from the `json` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint1: once the dataSchema is contructed, we can use the `.name` and `.dataType` properties to find its field name and field data type, respectively. Run the code example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 id StringType\n",
      "1 user StringType\n",
      "2 follower IntegerType\n",
      "3 friends IntegerType\n",
      "4 tweet StringType\n",
      "5 hashtag StringType\n",
      "6 ts TimestampType\n",
      "7 retweet IntegerType\n",
      "8 favorite IntegerType\n"
     ]
    }
   ],
   "source": [
    "for idx, field in enumerate(dataSchema): \n",
    "    print(idx, field.name, field.dataType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint2: notice you can use dot operator to index into the nested structure. Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[follower: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('json.follower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also works with bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'json.follower AS `follower`'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['json.follower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, create new columns with all the sub-fields from the `json` column by using a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, field in enumerate(dataSchema): \n",
    "    a = df.withColumn(field.name, df['json.' + field.name])\n",
    "    df=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- json: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |    |-- follower: integer (nullable = true)\n",
      " |    |-- friends: integer (nullable = true)\n",
      " |    |-- tweet: string (nullable = true)\n",
      " |    |-- hashtag: string (nullable = true)\n",
      " |    |-- ts: timestamp (nullable = true)\n",
      " |    |-- retweet: integer (nullable = true)\n",
      " |    |-- favorite: integer (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- follower: integer (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- hashtag: string (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- retweet: integer (nullable = true)\n",
      " |-- favorite: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checkout the schema after the update\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, clean the `df` DataFrame so that it only contains the sub-fileds from `json` column, and the `timestamp` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['user','id', 'follower','tweet', 'hashtag', 'ts', 'retweet', 'favorite','timestamp', 'friends'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- follower: integer (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- hashtag: string (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- retweet: integer (nullable = true)\n",
      " |-- favorite: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Run a query to find the occurences of each number of 'retweet'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweetCount =df.groupBy('retweet').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweetQuery = retweetCount.writeStream \\\n",
    "                  .outputMode('complete') \\\n",
    "                  .format('memory') \\\n",
    "                  .option('truncate', 'false') \\\n",
    "                  .queryName('retweetQuery') \\\n",
    "                  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   10|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   16|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   25|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   34|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   41|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   53|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   59|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   68|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|retweet|count|\n",
      "+-------+-----+\n",
      "|      0|   78|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df_ = spark.sql('SELECT * FROM retweetQuery')\n",
    "    df_.show(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Run a windowed query to find the number of occurences for each number of 'follower'. Use window size as 20 seconds, and sliding frequency as 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "followerCount = df.groupBy(\n",
    "    window(df['timestamp'],'1 minutes','30 seconds'),\n",
    "    df['follower']\n",
    ").count().orderBy('window')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "followerQuery = (followerCount.writeStream\n",
    "                  .outputMode('complete')\n",
    "                  .format('memory')\n",
    "                  .queryName('followerQuery')\n",
    "                  .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|window|follower|count|\n",
      "+------+--------+-----+\n",
      "+------+--------+-----+\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2220    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|1233    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|2220    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|299     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|1233    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|137     |2    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|14472   |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2220    |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|814     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|139371  |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|1233    |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|0       |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|2220    |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|28942   |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|255     |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2220    |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|814     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|7050    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|193     |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2717    |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|139371  |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|1233    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2220    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|857     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|814     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|7050    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|13      |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|193     |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|452     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|269     |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|550     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2220    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|857     |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|814     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|12380   |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|389     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|2836    |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|255     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|14215   |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|452     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|269     |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|389     |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|389     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|2836    |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|255     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|14215   |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|452     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|269     |1    |\n",
      "|[2020-11-09 00:20:00, 2020-11-09 00:20:20]|33      |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|389     |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|389     |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|18      |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|2836    |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|255     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|14215   |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|452     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|269     |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|1316    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------+--------+-----+\n",
      "|window                                    |follower|count|\n",
      "+------------------------------------------+--------+-----+\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|389     |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|18      |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|2836    |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|255     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|14215   |1    |\n",
      "|[2020-11-09 00:20:10, 2020-11-09 00:20:30]|2453    |1    |\n",
      "|[2020-11-09 00:20:20, 2020-11-09 00:20:40]|2185    |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|452     |1    |\n",
      "|[2020-11-09 00:20:30, 2020-11-09 00:20:50]|269     |1    |\n",
      "|[2020-11-09 00:20:40, 2020-11-09 00:21:00]|1316    |1    |\n",
      "+------------------------------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df_ = spark.sql('SELECT * FROM retweetQuery')\n",
    "    df_.show(10)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Analyze the sentiment of the tweets by using the TextBlob function.\n",
    "\n",
    "TextBlob help doc: [link](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, write a function that takes in a text input, and returns a sentiment of the input from the following array: ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    textblob = TextBlob(text).sentiment.polarity\n",
    "    if textblob < 0:\n",
    "        return 'negative'\n",
    "    elif textblob == 0:\n",
    "        return 'neutral'\n",
    "    elif textblob > 0:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second, use a UDF function to generate a new column for the streaming DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "sentiment_udf = udf(get_sentiment, StringType())\n",
    "\n",
    "\n",
    "df = df.withColumn('sentiment', sentiment_udf(df.tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- follower: integer (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- hashtag: string (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- retweet: integer (nullable = true)\n",
      " |-- favorite: integer (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lastly, run a query to find the count for each kind of sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentCount = df.groupBy('sentiment').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentQuery = sentimentCount.writeStream \\\n",
    "                  .outputMode('complete') \\\n",
    "                  .format('memory') \\\n",
    "                  .queryName('sentimentQuery') \\\n",
    "                  .start()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |1    |\n",
      "|neutral  |3    |\n",
      "|negative |1    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |1    |\n",
      "|neutral  |7    |\n",
      "|negative |2    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |6    |\n",
      "|neutral  |13   |\n",
      "|negative |4    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |7    |\n",
      "|neutral  |17   |\n",
      "|negative |6    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |10   |\n",
      "|neutral  |20   |\n",
      "|negative |8    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |13   |\n",
      "|neutral  |20   |\n",
      "|negative |9    |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |19   |\n",
      "|neutral  |26   |\n",
      "|negative |10   |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |25   |\n",
      "|neutral  |33   |\n",
      "|negative |11   |\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|positive |31   |\n",
      "|neutral  |34   |\n",
      "|negative |13   |\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can also use an infinitely loop instead to poll the results\n",
    "\n",
    "for i in range(10):\n",
    "    df = spark.sql('SELECT * FROM sentimentQuery')\n",
    "    df.show(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Show the sentiment analysis on a barplot dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Only works for Jupyter Notebooks!\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAHgCAYAAADQY9vNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZRElEQVR4nO3de7CkdX3n8c83DCgKXhB0FcVR1oqKQRTWgKQswZSl0fKKeCHe4sZN4nqJq5Zu3FxMTBlxL+oaFZVAsrIKrC5qRaMh6hp2FWcURAVjoqh4Q1QEL1HA7/7RD3pCDUwfpps+h9/rVUVN99O37/kVZ+o9z9PdT3V3AAC4cfuFVQ8AAMDyiT4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAWxZ9QAb3b777ttbt25d9RgAADu1ffv2S7p7vx3dJvp2YuvWrdm2bduqxwAA2Kmq+tK13ebwLgDAAEQfAMAARB8AwABEHwDAAEQfAMAARB8AwABEHwDAAEQfAMAARB8AwABEHwDAAEQfAMAARB8AwAC2rHqAje78i76dQ1/4l6seA4Aboe3HP2XVIzAQe/oAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGsOmir6p+q6qeMl1+WlXdYc1tb66qe65uOgCAjWnLqgdYr+5+w5qrT0vy6SRfm277t6uYCQBgo7tB9/RV1daquqCqTq6qT1XV6VV1s6p6UFV9sqrOq6oTq+om0/1fUVWfne77qmnbH1bVC6rqmCSHJXlrVZ1TVXtW1Yeq6rCq+u2qeuWa131aVb12uvzrVXX29Jg3VtVuN+QaAACswioO7/5ikhO6++AklyV5fpKTkjy+u38ps72Pv11V+yR5dJKDpvv+ydon6e7Tk2xLclx3H9LdP1pz8+lJHrPm+uOTvL2q7jFdPrK7D0lyVZLjrjlgVT2zqrZV1bYrf3j5Qn5oAIBVWkX0faW7z5ou/48kD0ryxe7+h2nbyUkekFkQ/nOSN1fVY5L8cN4X6O5vJflCVR1eVbfJLDTPml7r0CQfr6pzput33cHjT+juw7r7sC032/t6/ZAAABvJKt7T13PdqfvKqrpfZmH2hCT/PsnR63idtyc5NskFSd7Z3V1VleTk7n7JOmcGANjUVrGn74CqOmK6/MQkf5tka1X962nbk5N8uKr2SnLL7v7rJM9LcsgOnuvyJNe2K+4dSR41vcbbp21nJjmmqm6bJFW1T1XdeVd/IACAjW4Ve/rOT/LUqnpjks8neW6SjyY5raq2JPl4kjck2SfJGVV10ySV5Hd38FwnJXlDVf0oyRFrb+ju71bVZ5Pcs7vPnrZ9tqpemuT9VfULSa5I8qwkX1r8jwkAsHFU91xHWxfzYlVbk7ynu+91g73oLrr5v7pL3/3Jf7TqMQC4Edp+/FNWPQI3MlW1vbsP29Ftm+7LmQEAWL8b9PBud1+YZNPs5QMAuLGwpw8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAKIPAGAAog8AYACiDwBgAFtWPcBGd4873ibbjn/KqscAANgl9vQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AEADED0AQAMQPQBAAxgy6oH2Oh+8vXP5Msv+6VVjwEAbFIH/P55qx4hiT19AABDEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADEH0AAAMQfQAAAxB9AAADmCv6qurIebYBALAxzbun77VzbgMAYAPacl03VtURSe6fZL+qev6am26RZLdlDgYAwOJcZ/Ql2SPJXtP99l6z/bIkxyxrKAAAFus6o6+7P5zkw1V1Und/6QaaCQCABdvZnr6r3aSqTkiyde1juvvoZQwFAMBizRt9pyV5Q5I3J7lqeeMAALAM80bfld39+qVOAgDA0sz7lS3vrqrfqarbV9U+V/+31MkAAFiYeff0PXX684VrtnWSuy52HAAAlmGu6Ovuuyx7EAAAlmfe07DdrKpeOn2CN1V1t6p6+HJHAwBgUeZ9T99fJPlJZmfnSJKLkvzJUiYCAGDh5o2+A7v7lUmuSJLu/lGSWtpUAAAs1LzR95Oq2jOzD2+kqg5M8uOlTQUAwELN++ndP0jyviR3qqq3JjkyydOWNRQAAIs176d3P1BVn0hyeGaHdZ/b3ZcsdTIAABZm3sO7SbJ/kt2S7JHkAVX1mOWMBADAos21p6+qTkxycJLPJPnptLmTvGNJcwEAsEDzvqfv8O6+51InAQBgaeY9vPv/qmpDRl9Vba2qJ13Px35/0fMAAGxE8+7pOzmz8PtGZl/VUkm6uw9e2mTz25rkSUlOueYNVbWlu6+8wScCANhg5o2+E5M8Ocl5+fl7+nZJVW1N8t4kf5/ZmT6+muSRSe6Q5HVJ9kvywyS/2d0XVNVJSd7T3adPj/9+d++V5BVJ7lFV52QWp99N8rAkN01y86p6RJIzktw6ye5JXtrdZyziZwAA2Czmjb4vd/e7lvD6d0vyxO7+zao6Ncljkzw9yW919+er6peT/HmSo6/jOV6c5AXd/fAkqaqnJTkiycHd/Z2q2pLk0d19WVXtm+SjVfWu7u5re8KqemaSZybJ/rfcfdd/SgCAFZs3+i6oqlOSvDtrzsTR3bv66d0vdvc50+XtmR2qvX+S06p+dpa3m1yP5/1Ad39nulxJ/rSqHpDZXsr9k9wuyTeu7cHdfUKSE5Lk4P33vNY4BADYLOaNvj0zi70Hr9m2iK9sWXsqt6syi7FLu/uQHdz3ykwfPKlZEe5xHc/7gzWXj8vsUPGh3X1FVV2Y2aFfAIBhzHtGjqcve5DJZUm+WFWP6+7Tprg7uLvPTXJhkkOTnJrZe/+uPu56eZK9r+M5b5nk4in4jkpy56VNDwCwQV1n9FXVi7r7lVX12sz27P0L3f2cJcx0XJLXV9VLMwu7tyU5N8mbkpxRVWcnOTM/35v3qSRXVtW5SU7K7IMca701yburaluSc5JcsISZAQA2tJ3t6Tt/+nPbol+4uy9Mcq8111+15uaH7OD+38zs3L9Xe8m0/YokD7rG3U9a87hLMvtgx45m2GudYwMAbErXGX3d/e7p4g+7+7S1t1XV45Y2FQAACzXvGTleMuc2AAA2oJ29p++hSX4tyf5V9Zo1N90is0/TAgCwCezsPX1fy+z9fI/I7Hv0rnZ5kt9d1lAAACzWzt7Td26Sc6vqlOkDEwAAbELzfjnz/arqDzP7jrstmZ3lorv7rssaDACAxZk3+t6S2eHc7ZmdOQMAgE1k3uj7Xne/d6mTAACwNPNG3wer6vjMzrX7s/PldvcnljIVAAALNW/0/fL052FrtnWSoxc7DgAAyzBX9HX3UcseBACA5ZnrjBxVdbuqektVvXe6fs+qesZyRwMAYFHmPQ3bSUn+Jskdpuv/kOR5yxgIAIDFmzf69u3uU5P8NEm6+8r46hYAgE1j3uj7QVXdJrMPb6SqDk/yvaVNBQDAQs376d3nJ3lXkgOr6qwk+yU5ZmlTAQCwUPPu6TswyUOT3D+z9/Z9PvMHIwAAKzZv9P2n7r4sya2T/GqSE5K8fmlTAQCwUPNG39Uf2nhYkjd09xlJ9ljOSAAALNq80ffVqnpjkmOT/HVV3WQdjwUAYMXmDbdjM3sv30O6+9Ik+yR54dKmAgBgoeY9DdsPk7xjzfWvJ/n6soYCAGCxHKIFABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYgOgDABiA6AMAGIDoAwAYwJZVD7DR7XH7g3LA729b9RgAALvEnj4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAFsWfUAG90FF1+QI1975KrHACZnPfusVY8AsCnZ0wcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADAA0QcAMADRBwAwANEHADCATRt9VXWrqvqdNdfvUFWnr3ImAICNatNGX5JbJflZ9HX317r7mBXOAwCwYS0t+qpqa1WdX1VvqqrPVNX7q2rPqjqwqt5XVdur6iNVdffp/gdW1Uer6uNV9bKq+v60fa+qOrOqPlFV51XVI6eXeEWSA6vqnKo6fnq9T0+P+VhVHbRmlg9V1aFVdfOqOnF6jU+ueS4AgBu1Ze/pu1uS13X3QUkuTfLYJCckeXZ3H5rkBUn+fLrvq5O8urv/TZKvrXmOf07y6O6+b5KjkvznqqokL07yT919SHe/8Bqv+7YkxyZJVd0+yR26e3uS30vyd9NrHJXk+Kq6+TWHrqpnVtW2qtp2xfevWMAyAACs1rKj74vdfc50eXuSrUnun+S0qjonyRuT3H66/Ygkp02XT1nzHJXkT6vqU0n+Nsn+SW63k9c9NcnjpsvHrnneByd58fTaH0py0yQHXPPB3X1Cdx/W3Yftvtfuc/yYAAAb25YlP/+P11y+KrNYu7S7D1nHcxyXZL8kh3b3FVV1YWaxdq26+6tV9e2qOjjJ45P8u+mmSvLY7v7cOl4fAGDTu6E/yHFZki9W1eOSpGbuPd320cwO/ybJE9Y85pZJLp6C76gkd562X55k7+t4rbcleVGSW3b3edO2v0ny7OnwcKrqPrv6AwEAbAar+PTucUmeUVXnJvlMkqs/TPG8JM+vqrMzO+T7vWn7W5McVlXbpsdekCTd/e0kZ1XVp6vq+B28zumZxeOpa7b9cZLdk3xq+tDHHy/0JwMA2KCWdni3uy9Mcq8111+15uaH7OAhX01yeHd3VT0hybbpcZdk9n6/Hb3Gk66xae3rfTPX+Pm6+0f5+aFeAIBhLPs9fetxaJL/Ph16vTTJb6x4HgCAG40NE33d/ZEk997pHQEAWLfNfEYOAADmJPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAawZdUDbHR3v+3dc9azz1r1GAAAu8SePgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABiD4AgAGIPgCAAYg+AIABVHeveoYNraouT/K5Vc9xI7BvkktWPcQmZw0XwzouhnVcDOu466zhv3Tn7t5vRzdsuaEn2YQ+192HrXqIza6qtlnHXWMNF8M6LoZ1XAzruOus4fwc3gUAGIDoAwAYgOjbuRNWPcCNhHXcddZwMazjYljHxbCOu84azskHOQAABmBPHwDAAETftaiqh1TV56rqH6vqxaueZzOpqhOr6uKq+vSabftU1Qeq6vPTn7de5YwbXVXdqao+WFXnV9Vnquq503bruA5VddOqOruqzp3W8Y+m7Xepqo9N6/j2qtpj1bNudFW1W1V9sqreM123hutUVRdW1XlVdU5VbZu2+Z1ep6q6VVWdXlUXTH9HHmEd5yP6dqCqdkvyuiQPTXLPJE+sqnuudqpN5aQkD7nGthcnObO775bkzOk61+7KJP+hu++R5PAkz5r+H7SO6/PjJEd3972THJLkIVV1eJI/S/Jfp3X8bpJnrHDGzeK5Sc5fc90aXj9Hdfcha75ixO/0+r06yfu6++5J7p3Z/5fWcQ6ib8ful+Qfu/sL3f2TJG9L8sgVz7RpdPf/SfKda2x+ZJKTp8snJ3nUDTrUJtPdX+/uT0yXL8/sL7X9Yx3XpWe+P13dffqvkxyd5PRpu3Xciaq6Y5KHJXnzdL1iDRfF7/Q6VNUtkjwgyVuSpLt/0t2XxjrORfTt2P5JvrLm+kXTNq6/23X315NZ0CS57Yrn2TSqamuS+yT5WKzjuk2HJc9JcnGSDyT5pySXdveV0138fu/cf0vyoiQ/na7fJtbw+ugk76+q7VX1zGmb3+n1uWuSbyX5i+ntBm+uqpvHOs5F9O1Y7WCbjzlzg6uqvZL8ryTP6+7LVj3PZtTdV3X3IUnumNle/Hvs6G437FSbR1U9PMnF3b197eYd3NUa7tyR3X3fzN469KyqesCqB9qEtiS5b5LXd/d9kvwgDuXOTfTt2EVJ7rTm+h2TfG1Fs9xYfLOqbp8k058Xr3ieDa+qds8s+N7a3e+YNlvH62k6BPShzN4jeauquvo0lH6/r9uRSR5RVRdm9laXozPb82cN16m7vzb9eXGSd2b2jxC/0+tzUZKLuvtj0/XTM4tA6zgH0bdjH09yt+nTaXskeUKSd614ps3uXUmeOl1+apIzVjjLhje9Z+otSc7v7v+y5ibruA5VtV9V3Wq6vGeSX83s/ZEfTHLMdDfreB26+yXdfcfu3prZ34V/193HxRquS1XdvKr2vvpykgcn+XT8Tq9Ld38jyVeq6henTQ9K8tlYx7n4cuZrUVW/ltm/ZndLcmJ3v3zFI20aVfU/kzwwyb5JvpnkD5L87ySnJjkgyZeTPK67r/lhDyZV9StJPpLkvPz8fVT/MbP39VnHOVXVwZm9qXu3zP6Re2p3v6yq7prZXqt9knwyya93949XN+nmUFUPTPKC7n64NVyfab3eOV3dkuSU7n55Vd0mfqfXpaoOyexDRXsk+UKSp2f6/Y51vE6iDwBgAA7vAgAMQPQBAAxA9AEADED0AQAMQPQBAAxA9AFsYFX1vKq62arnADY/X9kCsIFNZ8I4rLsvWfUswOZmTx/ALqqqp1TVp6rq3Kr6q6q6c1WdOW07s6oOmO53UlUds+Zx35/+fGBVfaiqTq+qC6rqrTXznCR3SPLBqvrgan464MZiy87vAsC1qaqDkvxekiO7+5Kq2iezs4D8ZXefXFW/keQ1SR61k6e6T5KDMjuH7VnT872mqp6f5Ch7+oBdZU8fwK45OsnpV0fZdOqnI5KcMt3+V0l+ZY7nObu7L+runyY5J8nWJcwKDEz0AeyaSrKzN0dfffuVmf7erarK7NyhV1t73tqr4kgMsGCiD2DXnJnk2Kq6TZJMh3f/b5InTLcfl+Tvp8sXJjl0uvzIJLvP8fyXJ9l7UcMC4/IvSYBd0N2fqaqXJ/lwVV2V5JNJnpPkxKp6YZJvJXn6dPc3JTmjqs7OLBZ/MMdLnJDkvVX19e4+avE/ATAKX9kCADAAh3cBAAYg+gAABiD6AAAGIPoAAAYg+gAABiD6AAAGIPoAAAYg+gAABvD/AbTFGyQqPG/SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df = spark.sql('SELECT * FROM sentimentQuery')\n",
    "    df_pd = df.toPandas()\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sns.barplot(data = df_pd, y='sentiment', x='count')\n",
    "    plt.show()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop all queries\n",
    "retweetQuery.stop()\n",
    "followerQuery.stop()\n",
    "sentimentQuery.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Job!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
