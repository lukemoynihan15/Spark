{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46da2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init('/opt/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8949bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937b1a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 11:32:28 WARN Utils: Your hostname, GPUServer resolves to a loopback address: 127.0.1.1; using 10.4.10.8 instead (on interface enp2s0)\n",
      "22/04/22 11:32:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.0.1/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/04/22 11:32:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/04/22 11:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('lec_23_moynihan_ex1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0124a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from your netcat socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8602c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 11:35:43 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "lines = spark.readStream\\\n",
    ".format('socket').option('host','localhost')\\\n",
    ".option('port',6969).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df27c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a1d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f1e0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.select(explode(split(lines.value, \" \")).alias('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7b27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f511ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = words.groupBy('words').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "784ed855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 11:45:38 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-5fbb306a-1846-4e45-8f7e-d1fd00ff4761. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#start tbhed query\n",
    "\n",
    "query = (wordCounts.writeStream\n",
    "         .outputMode('complete')\n",
    "         .format('memory')\n",
    "         .queryName('wordCounts')\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "208f175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:=================================>                   (126 + 24) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|  not|    1|\n",
      "|  fun|    1|\n",
      "| hate|    1|\n",
      "|   is|    1|\n",
      "|   it|    1|\n",
      "|spark|    1|\n",
      "|    i|    1|\n",
      "|   at|    1|\n",
      "|  all|    1|\n",
      "|     |    1|\n",
      "+-----+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|  words|count|\n",
      "+-------+-----+\n",
      "|   even|    2|\n",
      "|    not|    3|\n",
      "|anymore|    1|\n",
      "|    fun|    1|\n",
      "|   hate|    1|\n",
      "|     is|    4|\n",
      "|    bad|    1|\n",
      "|    any|    1|\n",
      "|     it|    3|\n",
      "|  spark|    2|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "wordCounts.createOrReplaceTempView('wc')\n",
    "\n",
    "for x in range(10):\n",
    "    df = spark.sql('SELECT * FROM wordCounts')\n",
    "    df.show(10)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6a0def7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41fa68e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50fe1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8483dc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0675e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
