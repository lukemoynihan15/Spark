{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4b8d88",
   "metadata": {},
   "source": [
    "# NLP with SPark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1b3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14549ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 11:34:21 WARN Utils: Your hostname, GPUServer resolves to a loopback address: 127.0.1.1; using 10.4.10.8 instead (on interface enp2s0)\n",
      "22/04/08 11:34:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.0.1/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/04/08 11:34:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/04/08 11:34:22 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('nlp_spark_moynihanl').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3add6",
   "metadata": {},
   "source": [
    "## 1 . Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab2f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus as input and trying to take a line at a time and dividing into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa7d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_pickle('corpus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec23af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies and gentlemen please welcome to the sta...</td>\n",
       "      <td>Ali Wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank you thank you thank you san francisco th...</td>\n",
       "      <td>Anthony Jeselnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>all right thank you thank you very much thank...</td>\n",
       "      <td>Bill Burr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>bo what old macdonald had a farm e i e i o and...</td>\n",
       "      <td>Bo Burnham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>this is dave he tells dirty jokes for a living...</td>\n",
       "      <td>Dave Chappelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats up davis whats up im home i had to bri...</td>\n",
       "      <td>Hasan Minhaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies and gentlemen please welcome to the ...</td>\n",
       "      <td>Jim Jefferies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies and gentlemen welcome joe rogan  wha...</td>\n",
       "      <td>Joe Rogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>all right petunia wish me luck out there you w...</td>\n",
       "      <td>John Mulaney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>intro fade the music out lets roll hold there ...</td>\n",
       "      <td>Louis C.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thank you thanks thank you guys hey se...</td>\n",
       "      <td>Mike Birbiglia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello hello how you doing great thank you wow ...</td>\n",
       "      <td>Ricky Gervais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript         full_name\n",
       "ali      ladies and gentlemen please welcome to the sta...          Ali Wong\n",
       "anthony  thank you thank you thank you san francisco th...  Anthony Jeselnik\n",
       "bill      all right thank you thank you very much thank...         Bill Burr\n",
       "bo       bo what old macdonald had a farm e i e i o and...        Bo Burnham\n",
       "dave     this is dave he tells dirty jokes for a living...    Dave Chappelle\n",
       "hasan      whats up davis whats up im home i had to bri...      Hasan Minhaj\n",
       "jim         ladies and gentlemen please welcome to the ...     Jim Jefferies\n",
       "joe         ladies and gentlemen welcome joe rogan  wha...         Joe Rogan\n",
       "john     all right petunia wish me luck out there you w...      John Mulaney\n",
       "louis    intro fade the music out lets roll hold there ...        Louis C.K.\n",
       "mike     wow hey thank you thanks thank you guys hey se...    Mike Birbiglia\n",
       "ricky    hello hello how you doing great thank you wow ...     Ricky Gervais"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eafc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>transcript</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ali</td>\n",
       "      <td>ladies and gentlemen please welcome to the sta...</td>\n",
       "      <td>Ali Wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthony</td>\n",
       "      <td>thank you thank you thank you san francisco th...</td>\n",
       "      <td>Anthony Jeselnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bill</td>\n",
       "      <td>all right thank you thank you very much thank...</td>\n",
       "      <td>Bill Burr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bo</td>\n",
       "      <td>bo what old macdonald had a farm e i e i o and...</td>\n",
       "      <td>Bo Burnham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dave</td>\n",
       "      <td>this is dave he tells dirty jokes for a living...</td>\n",
       "      <td>Dave Chappelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hasan</td>\n",
       "      <td>whats up davis whats up im home i had to bri...</td>\n",
       "      <td>Hasan Minhaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jim</td>\n",
       "      <td>ladies and gentlemen please welcome to the ...</td>\n",
       "      <td>Jim Jefferies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>joe</td>\n",
       "      <td>ladies and gentlemen welcome joe rogan  wha...</td>\n",
       "      <td>Joe Rogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>john</td>\n",
       "      <td>all right petunia wish me luck out there you w...</td>\n",
       "      <td>John Mulaney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>louis</td>\n",
       "      <td>intro fade the music out lets roll hold there ...</td>\n",
       "      <td>Louis C.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mike</td>\n",
       "      <td>wow hey thank you thanks thank you guys hey se...</td>\n",
       "      <td>Mike Birbiglia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ricky</td>\n",
       "      <td>hello hello how you doing great thank you wow ...</td>\n",
       "      <td>Ricky Gervais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         transcript  \\\n",
       "0       ali  ladies and gentlemen please welcome to the sta...   \n",
       "1   anthony  thank you thank you thank you san francisco th...   \n",
       "2      bill   all right thank you thank you very much thank...   \n",
       "3        bo  bo what old macdonald had a farm e i e i o and...   \n",
       "4      dave  this is dave he tells dirty jokes for a living...   \n",
       "5     hasan    whats up davis whats up im home i had to bri...   \n",
       "6       jim     ladies and gentlemen please welcome to the ...   \n",
       "7       joe     ladies and gentlemen welcome joe rogan  wha...   \n",
       "8      john  all right petunia wish me luck out there you w...   \n",
       "9     louis  intro fade the music out lets roll hold there ...   \n",
       "10     mike  wow hey thank you thanks thank you guys hey se...   \n",
       "11    ricky  hello hello how you doing great thank you wow ...   \n",
       "\n",
       "           full_name  \n",
       "0           Ali Wong  \n",
       "1   Anthony Jeselnik  \n",
       "2          Bill Burr  \n",
       "3         Bo Burnham  \n",
       "4     Dave Chappelle  \n",
       "5       Hasan Minhaj  \n",
       "6      Jim Jefferies  \n",
       "7          Joe Rogan  \n",
       "8       John Mulaney  \n",
       "9         Louis C.K.  \n",
       "10    Mike Birbiglia  \n",
       "11     Ricky Gervais  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.reset_index(inplace=True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be30b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = spark.createDataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab49887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------+----------------+\n",
      "|  index|                                        transcript|       full_name|\n",
      "+-------+--------------------------------------------------+----------------+\n",
      "|    ali|ladies and gentlemen please welcome to the stag...|        Ali Wong|\n",
      "|anthony|thank you thank you thank you san francisco tha...|Anthony Jeselnik|\n",
      "|   bill| all right thank you thank you very much thank ...|       Bill Burr|\n",
      "|     bo|bo what old macdonald had a farm e i e i o and ...|      Bo Burnham|\n",
      "|   dave|this is dave he tells dirty jokes for a living ...|  Dave Chappelle|\n",
      "|  hasan|  whats up davis whats up im home i had to brin...|    Hasan Minhaj|\n",
      "|    jim|   ladies and gentlemen please welcome to the s...|   Jim Jefferies|\n",
      "|    joe|   ladies and gentlemen welcome joe rogan  what...|       Joe Rogan|\n",
      "|   john|all right petunia wish me luck out there you wi...|    John Mulaney|\n",
      "|  louis|intro fade the music out lets roll hold there l...|      Louis C.K.|\n",
      "|   mike|wow hey thank you thanks thank you guys hey sea...|  Mike Birbiglia|\n",
      "|  ricky|hello hello how you doing great thank you wow c...|   Ricky Gervais|\n",
      "+-------+--------------------------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.show(truncate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2342792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71cb361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = 'transcript', outputCol = 'words')\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol = 'transcript', outputCol = 'words',\n",
    "                               pattern = '\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a4f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = F.udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83f59f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|          transcript|               words|tokens|\n",
      "+--------------------+--------------------+------+\n",
      "|ladies and gentle...|[ladies, and, gen...|  7369|\n",
      "|thank you thank y...|[thank, you, than...|  6720|\n",
      "| all right thank ...|[, all, right, th...| 12180|\n",
      "|bo what old macdo...|[bo, what, old, m...|  6929|\n",
      "|this is dave he t...|[this, is, dave, ...|  9166|\n",
      "|  whats up davis ...|[, , whats, up, d...| 10413|\n",
      "|   ladies and gen...|[, , , ladies, an...| 11016|\n",
      "|   ladies and gen...|[, , , ladies, an...|  9923|\n",
      "|all right petunia...|[all, right, petu...|  9302|\n",
      "|intro fade the mu...|[intro, fade, the...|  7487|\n",
      "|wow hey thank you...|[wow, hey, thank,...| 11454|\n",
      "|hello hello how y...|[hello, hello, ho...| 10529|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:======================================================>  (18 + 1) / 19]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer.transform(corpus)\n",
    "\n",
    "tokenized.select(['transcript', 'words']).withColumn('tokens', countTokens(tokenized['words'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c0be289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|          transcript|               words|tokens|\n",
      "+--------------------+--------------------+------+\n",
      "|ladies and gentle...|[ladies, and, gen...|  7339|\n",
      "|thank you thank y...|[thank, you, than...|  6675|\n",
      "| all right thank ...|[all, right, than...| 12040|\n",
      "|bo what old macdo...|[bo, what, old, m...|  6615|\n",
      "|this is dave he t...|[this, is, dave, ...|  9010|\n",
      "|  whats up davis ...|[whats, up, davis...| 10267|\n",
      "|   ladies and gen...|[ladies, and, gen...| 10855|\n",
      "|   ladies and gen...|[ladies, and, gen...|  9826|\n",
      "|all right petunia...|[all, right, petu...|  9240|\n",
      "|intro fade the mu...|[intro, fade, the...|  7455|\n",
      "|wow hey thank you...|[wow, hey, thank,...| 11400|\n",
      "|hello hello how y...|[hello, hello, ho...| 10539|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenized = regexTokenizer.transform(corpus)\n",
    "\n",
    "regexTokenized.select(['transcript', 'words']).withColumn('tokens', countTokens(regexTokenized['words'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf74c2",
   "metadata": {},
   "source": [
    "## Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc4c05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cv_no_stop = pickle.load(open('cv_no_stop.pkl', 'rb'))\n",
    "\n",
    "stop_words = list(cv_no_stop.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c157e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couldnt',\n",
       " 'others',\n",
       " 'whereafter',\n",
       " 'keep',\n",
       " 'had',\n",
       " 'formerly',\n",
       " 'thick',\n",
       " 'were',\n",
       " 'somehow',\n",
       " 'often',\n",
       " 'per',\n",
       " 'enough',\n",
       " 'thereby',\n",
       " 'see',\n",
       " 'first',\n",
       " 'of',\n",
       " 'thus',\n",
       " 'although',\n",
       " 'above',\n",
       " 'last',\n",
       " 'do',\n",
       " 'whereas',\n",
       " 'hence',\n",
       " 'amongst',\n",
       " 'whatever',\n",
       " 'well',\n",
       " 'four',\n",
       " 'whoever',\n",
       " 'else',\n",
       " 'thru',\n",
       " 'nowhere',\n",
       " 'same',\n",
       " 'detail',\n",
       " 'other',\n",
       " 'its',\n",
       " 'whether',\n",
       " 'dont',\n",
       " 'side',\n",
       " 'which',\n",
       " 'i',\n",
       " 'latterly',\n",
       " 'anyone',\n",
       " 'amoungst',\n",
       " 'by',\n",
       " 'beyond',\n",
       " 'co',\n",
       " 'via',\n",
       " 'behind',\n",
       " 'and',\n",
       " 'hereupon',\n",
       " 'toward',\n",
       " 'ltd',\n",
       " 'became',\n",
       " 'perhaps',\n",
       " 'think',\n",
       " 'oh',\n",
       " 'more',\n",
       " 'afterwards',\n",
       " 'we',\n",
       " 'seemed',\n",
       " 'still',\n",
       " 'move',\n",
       " 'off',\n",
       " 'go',\n",
       " 'seem',\n",
       " 'after',\n",
       " 'until',\n",
       " 'somewhere',\n",
       " 'describe',\n",
       " 'with',\n",
       " 'eight',\n",
       " 'sometimes',\n",
       " 'own',\n",
       " 'one',\n",
       " 'time',\n",
       " 'whereby',\n",
       " 'throughout',\n",
       " 'wherein',\n",
       " 'just',\n",
       " 'yours',\n",
       " 'cry',\n",
       " 'may',\n",
       " 'at',\n",
       " 'will',\n",
       " 'upon',\n",
       " 'fifteen',\n",
       " 'towards',\n",
       " 'hasnt',\n",
       " 'it',\n",
       " 'not',\n",
       " 'nor',\n",
       " 'latter',\n",
       " 'she',\n",
       " 'no',\n",
       " 'forty',\n",
       " 'less',\n",
       " 'hundred',\n",
       " 'a',\n",
       " 'can',\n",
       " 'noone',\n",
       " 'again',\n",
       " 'like',\n",
       " 'those',\n",
       " 'indeed',\n",
       " 'get',\n",
       " 'whereupon',\n",
       " 'bill',\n",
       " 'on',\n",
       " 'their',\n",
       " 'together',\n",
       " 'already',\n",
       " 'should',\n",
       " 'yeah',\n",
       " 'myself',\n",
       " 'five',\n",
       " 'interest',\n",
       " 'part',\n",
       " 'except',\n",
       " 'eleven',\n",
       " 'as',\n",
       " 'mine',\n",
       " 'nothing',\n",
       " 'therein',\n",
       " 'un',\n",
       " 'know',\n",
       " 'how',\n",
       " 'much',\n",
       " 'for',\n",
       " 'either',\n",
       " 'thence',\n",
       " 'show',\n",
       " 'sometime',\n",
       " 'however',\n",
       " 'beforehand',\n",
       " 'con',\n",
       " 'nobody',\n",
       " 'third',\n",
       " 'out',\n",
       " 'im',\n",
       " 'people',\n",
       " 'former',\n",
       " 'he',\n",
       " 'alone',\n",
       " 'nine',\n",
       " 'name',\n",
       " 'hereafter',\n",
       " 'fire',\n",
       " 'up',\n",
       " 'ever',\n",
       " 'to',\n",
       " 'my',\n",
       " 'once',\n",
       " 'becoming',\n",
       " 'many',\n",
       " 'amount',\n",
       " 'elsewhere',\n",
       " 'fill',\n",
       " 'his',\n",
       " 'why',\n",
       " 'least',\n",
       " 'mill',\n",
       " 'they',\n",
       " 'then',\n",
       " 'over',\n",
       " 'around',\n",
       " 'each',\n",
       " 'this',\n",
       " 'full',\n",
       " 'these',\n",
       " 'themselves',\n",
       " 'whole',\n",
       " 'or',\n",
       " 'several',\n",
       " 'moreover',\n",
       " 'must',\n",
       " 'namely',\n",
       " 'ourselves',\n",
       " 'got',\n",
       " 'her',\n",
       " 'all',\n",
       " 'even',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'cant',\n",
       " 'cannot',\n",
       " 'rather',\n",
       " 'become',\n",
       " 'meanwhile',\n",
       " 'too',\n",
       " 'almost',\n",
       " 'itself',\n",
       " 'whom',\n",
       " 'system',\n",
       " 'your',\n",
       " 'sincere',\n",
       " 'me',\n",
       " 'ours',\n",
       " 'inc',\n",
       " 'thereafter',\n",
       " 'something',\n",
       " 'where',\n",
       " 'him',\n",
       " 'next',\n",
       " 'ie',\n",
       " 'anyhow',\n",
       " 'below',\n",
       " 'while',\n",
       " 'put',\n",
       " 'so',\n",
       " 'back',\n",
       " 'youre',\n",
       " 'against',\n",
       " 'done',\n",
       " 'be',\n",
       " 'the',\n",
       " 'give',\n",
       " 'none',\n",
       " 'call',\n",
       " 'being',\n",
       " 'becomes',\n",
       " 'etc',\n",
       " 'fifty',\n",
       " 'find',\n",
       " 'beside',\n",
       " 'any',\n",
       " 're',\n",
       " 'both',\n",
       " 'yet',\n",
       " 'during',\n",
       " 'might',\n",
       " 'everyone',\n",
       " 'here',\n",
       " 'under',\n",
       " 'among',\n",
       " 'yourselves',\n",
       " 'within',\n",
       " 'therefore',\n",
       " 'them',\n",
       " 'top',\n",
       " 'herein',\n",
       " 'are',\n",
       " 'whose',\n",
       " 'am',\n",
       " 'than',\n",
       " 'six',\n",
       " 'three',\n",
       " 'an',\n",
       " 'someone',\n",
       " 'our',\n",
       " 'such',\n",
       " 'always',\n",
       " 'take',\n",
       " 'when',\n",
       " 'said',\n",
       " 'besides',\n",
       " 'empty',\n",
       " 'made',\n",
       " 'between',\n",
       " 'into',\n",
       " 'been',\n",
       " 'seeming',\n",
       " 'without',\n",
       " 'most',\n",
       " 'wherever',\n",
       " 'us',\n",
       " 'from',\n",
       " 'though',\n",
       " 'could',\n",
       " 'also',\n",
       " 'down',\n",
       " 'every',\n",
       " 'hers',\n",
       " 'front',\n",
       " 'thereupon',\n",
       " 'some',\n",
       " 'before',\n",
       " 'neither',\n",
       " 'right',\n",
       " 'hereby',\n",
       " 'gonna',\n",
       " 'whither',\n",
       " 'two',\n",
       " 'never',\n",
       " 'what',\n",
       " 'whence',\n",
       " 'because',\n",
       " 'anyway',\n",
       " 'otherwise',\n",
       " 'serious',\n",
       " 'seems',\n",
       " 'but',\n",
       " 'ten',\n",
       " 'everywhere',\n",
       " 'twelve',\n",
       " 'that',\n",
       " 'herself',\n",
       " 'was',\n",
       " 'everything',\n",
       " 'found',\n",
       " 'anything',\n",
       " 'bottom',\n",
       " 'whenever',\n",
       " 'along',\n",
       " 'about',\n",
       " 'few',\n",
       " 'sixty',\n",
       " 'across',\n",
       " 'very',\n",
       " 'another',\n",
       " 'who',\n",
       " 'yourself',\n",
       " 'anywhere',\n",
       " 'since',\n",
       " 'through',\n",
       " 'nevertheless',\n",
       " 'onto',\n",
       " 'is',\n",
       " 'twenty',\n",
       " 'please',\n",
       " 'mostly',\n",
       " 'due',\n",
       " 'you',\n",
       " 'have',\n",
       " 'in',\n",
       " 'only',\n",
       " 'now',\n",
       " 'there',\n",
       " 'would',\n",
       " 'further',\n",
       " 'eg',\n",
       " 'de',\n",
       " 'has',\n",
       " 'thin',\n",
       " 'himself']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62c263e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4cc9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol = 'words',outputCol = 'no_stop_words',\n",
    "                          stopWords = stop_words\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a2300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_no_stop = remover.transform(regexTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1ac0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+--------------------+\n",
      "|  index|          transcript|       full_name|               words|       no_stop_words|\n",
      "+-------+--------------------+----------------+--------------------+--------------------+\n",
      "|    ali|ladies and gentle...|        Ali Wong|[ladies, and, gen...|[ladies, gentleme...|\n",
      "|anthony|thank you thank y...|Anthony Jeselnik|[thank, you, than...|[thank, thank, th...|\n",
      "|   bill| all right thank ...|       Bill Burr|[all, right, than...|[thank, thank, th...|\n",
      "|     bo|bo what old macdo...|      Bo Burnham|[bo, what, old, m...|[bo, old, macdona...|\n",
      "|   dave|this is dave he t...|  Dave Chappelle|[this, is, dave, ...|[dave, tells, dir...|\n",
      "|  hasan|  whats up davis ...|    Hasan Minhaj|[whats, up, davis...|[whats, davis, wh...|\n",
      "|    jim|   ladies and gen...|   Jim Jefferies|[ladies, and, gen...|[ladies, gentleme...|\n",
      "|    joe|   ladies and gen...|       Joe Rogan|[ladies, and, gen...|[ladies, gentleme...|\n",
      "|   john|all right petunia...|    John Mulaney|[all, right, petu...|[petunia, wish, l...|\n",
      "|  louis|intro fade the mu...|      Louis C.K.|[intro, fade, the...|[intro, fade, mus...|\n",
      "|   mike|wow hey thank you...|  Mike Birbiglia|[wow, hey, thank,...|[wow, hey, thank,...|\n",
      "|  ricky|hello hello how y...|   Ricky Gervais|[hello, hello, ho...|[hello, hello, do...|\n",
      "+-------+--------------------+----------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_no_stop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f8bb4",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2f2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35acd4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|                                                    bi-grams|\n",
      "+------------------------------------------------------------+\n",
      "|[ladies gentlemen, gentlemen welcome, welcome stage, stag...|\n",
      "|[thank thank, thank thank, thank san, san francisco, fran...|\n",
      "|[thank thank, thank thank, thank thank, thank thank, than...|\n",
      "|[bo old, old macdonald, macdonald farm, farm e, e e, e o,...|\n",
      "|[dave tells, tells dirty, dirty jokes, jokes living, livi...|\n",
      "|[whats davis, davis whats, whats home, home bring, bring ...|\n",
      "|[ladies gentlemen, gentlemen welcome, welcome stage, stag...|\n",
      "|[ladies gentlemen, gentlemen welcome, welcome joe, joe ro...|\n",
      "|[petunia wish, wish luck, luck die, die august, august pr...|\n",
      "|[intro fade, fade music, music lets, lets roll, roll hold...|\n",
      "|[wow hey, hey thank, thank thanks, thanks thank, thank gu...|\n",
      "|[hello hello, hello doing, doing great, great thank, than...|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n = 2, inputCol='no_stop_words',outputCol='bi-grams')\n",
    "\n",
    "ngramDF = ngram.transform(tokenized_no_stop)\n",
    "ngramDF.select('bi-grams').show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98adb003",
   "metadata": {},
   "source": [
    "## Feature Extractors\n",
    "#### TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c866b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9af658ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='no_stop_words', outputCol='tf', numFeatures = 1000)\n",
    "\n",
    "tfData = hashingTF.transform(ngramDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1f792cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol = 'tf', outputCol = 'tfidf', minDocFreq = 3)\n",
    "\n",
    "idfModel = idf.fit(tfData)\n",
    "\n",
    "rescaledData = idfModel.transform(tfData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c93403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------+\n",
      "|  index|                                             tfidf|\n",
      "+-------+--------------------------------------------------+\n",
      "|    ali|(1000,[0,1,2,3,4,5,7,9,10,11,15,16,19,21,22,23,...|\n",
      "|anthony|(1000,[0,2,3,7,8,10,12,15,18,20,21,22,23,25,27,...|\n",
      "|   bill|(1000,[0,1,2,3,4,5,6,7,10,11,13,14,15,16,17,21,...|\n",
      "|     bo|(1000,[0,1,2,6,7,9,12,13,15,16,18,19,21,22,23,2...|\n",
      "|   dave|(1000,[0,1,2,4,6,7,9,10,11,12,14,16,20,21,22,23...|\n",
      "|  hasan|(1000,[0,1,2,5,7,10,12,14,15,16,17,18,19,20,22,...|\n",
      "|    jim|(1000,[0,1,3,7,8,9,10,12,14,15,16,17,18,19,20,2...|\n",
      "|    joe|(1000,[0,1,2,7,10,13,14,16,19,21,22,23,24,25,27...|\n",
      "|   john|(1000,[0,1,3,4,7,9,10,14,15,16,21,22,23,24,25,2...|\n",
      "|  louis|(1000,[0,2,3,5,9,11,12,14,15,16,17,20,22,24,25,...|\n",
      "|   mike|(1000,[0,1,4,6,7,8,9,10,12,13,14,16,19,20,21,22...|\n",
      "|  ricky|(1000,[0,1,2,3,4,5,6,7,10,11,12,16,17,18,19,20,...|\n",
      "+-------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(['index','tfidf']).show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480609c",
   "metadata": {},
   "source": [
    "### CountVecorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6477d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06d1606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol = 'no_stop_words', outputCol = 'counts', \n",
    "                    vocabSize=1000,\n",
    "                    minDF = 3.0,\n",
    "                    maxDF = 10,\n",
    "                    minTF = 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "523a2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(ngramDF)\n",
    "\n",
    "result = cvModel.transform(ngramDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acd9f2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------+\n",
      "|  index|                                            counts|\n",
      "+-------+--------------------------------------------------+\n",
      "|    ali|(1000,[0,3,4,5,6,8,9,10,11,12,13,14,17,18,19,20...|\n",
      "|anthony|(1000,[0,1,2,3,5,7,8,10,11,12,13,15,16,18,21,24...|\n",
      "|   bill|(1000,[0,1,2,3,4,5,6,7,10,11,15,16,18,20,21,25,...|\n",
      "|     bo|(1000,[2,3,5,7,9,10,12,13,19,21,23,24,25,26,29,...|\n",
      "|   dave|(1000,[0,1,2,4,6,10,12,14,16,17,21,22,23,24,25,...|\n",
      "|  hasan|(1000,[1,2,3,4,8,9,10,11,12,14,15,16,18,21,23,2...|\n",
      "|    jim|(1000,[0,1,2,3,5,7,9,12,13,14,16,17,18,20,21,22...|\n",
      "|    joe|(1000,[0,1,2,3,4,5,6,8,9,10,11,13,14,15,16,17,2...|\n",
      "|   john|(1000,[0,1,2,3,6,8,11,12,13,14,15,18,20,21,22,2...|\n",
      "|  louis|(1000,[0,1,3,4,5,6,10,11,14,15,17,19,20,24,32,3...|\n",
      "|   mike|(1000,[0,2,6,9,11,12,14,15,16,17,18,23,24,27,29...|\n",
      "|  ricky|(1000,[0,1,2,3,5,7,9,11,13,14,15,18,20,21,23,25...|\n",
      "+-------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(['index','counts']).show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac8878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
