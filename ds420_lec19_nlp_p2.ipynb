{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> DS420 - Lec 19: Natural Language Processing (Part II)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do **Latent Dirichlet Allocation (LDA)**, which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>...</th>\n",
       "      <th>zee</th>\n",
       "      <th>zen</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 7392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaah  aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aaah  aah  abc  \\\n",
       "ali           0             0                 0          0     0    0    1   \n",
       "anthony       0             0                 0          0     0    0    0   \n",
       "bill          1             0                 0          0     0    0    0   \n",
       "bo            0             1                 1          1     0    0    0   \n",
       "dave          0             0                 0          0     1    0    0   \n",
       "hasan         0             0                 0          0     0    0    0   \n",
       "jim           0             0                 0          0     0    0    0   \n",
       "joe           0             0                 0          0     0    0    0   \n",
       "john          0             0                 0          0     0    0    0   \n",
       "louis         0             0                 0          0     0    3    0   \n",
       "mike          0             0                 0          0     0    0    0   \n",
       "ricky         0             0                 0          0     0    0    0   \n",
       "\n",
       "         abcs  ability  abject  ...  zee  zen  zeppelin  zero  zillion  \\\n",
       "ali         0        0       0  ...    0    0         0     0        0   \n",
       "anthony     0        0       0  ...    0    0         0     0        0   \n",
       "bill        1        0       0  ...    0    0         0     1        1   \n",
       "bo          0        1       0  ...    0    0         0     1        0   \n",
       "dave        0        0       0  ...    0    0         0     0        0   \n",
       "hasan       0        0       0  ...    2    1         0     1        0   \n",
       "jim         0        0       0  ...    0    0         0     0        0   \n",
       "joe         0        0       0  ...    0    0         0     0        0   \n",
       "john        0        0       0  ...    0    0         0     0        0   \n",
       "louis       0        0       0  ...    0    0         0     2        0   \n",
       "mike        0        0       0  ...    0    0         2     1        0   \n",
       "ricky       0        1       1  ...    0    0         0     0        0   \n",
       "\n",
       "         zombie  zombies  zoning  zoo  éclair  \n",
       "ali           1        0       0    0       0  \n",
       "anthony       0        0       0    0       0  \n",
       "bill          1        1       1    0       0  \n",
       "bo            0        0       0    0       0  \n",
       "dave          0        0       0    0       0  \n",
       "hasan         0        0       0    0       0  \n",
       "jim           0        0       0    0       0  \n",
       "joe           0        0       0    0       0  \n",
       "john          0        0       0    0       1  \n",
       "louis         0        0       0    0       0  \n",
       "mike          0        0       0    0       0  \n",
       "ricky         0        0       0    1       0  \n",
       "\n",
       "[12 rows x 7392 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_no_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'open' from 'smart_open' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1aacbe00a9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the necessary modules for LDA with gensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lip/anaconda3/lib/python3.7/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lip/anaconda3/lib/python3.7/site-packages/gensim/parsing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[1;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lip/anaconda3/lib/python3.7/site-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lip/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'open' from 'smart_open' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ali</th>\n",
       "      <th>anthony</th>\n",
       "      <th>bill</th>\n",
       "      <th>bo</th>\n",
       "      <th>dave</th>\n",
       "      <th>hasan</th>\n",
       "      <th>jim</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>louis</th>\n",
       "      <th>mike</th>\n",
       "      <th>ricky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ali  anthony  bill  bo  dave  hasan  jim  joe  john  louis  \\\n",
       "aaaaah              0        0     1   0     0      0    0    0     0      0   \n",
       "aaaaahhhhhhh        0        0     0   1     0      0    0    0     0      0   \n",
       "aaaaauuugghhhhhh    0        0     0   1     0      0    0    0     0      0   \n",
       "aaaahhhhh           0        0     0   1     0      0    0    0     0      0   \n",
       "aaah                0        0     0   0     1      0    0    0     0      0   \n",
       "\n",
       "                  mike  ricky  \n",
       "aaaaah               0      0  \n",
       "aaaaahhhhhhh         0      0  \n",
       "aaaaauuugghhhhhh     0      0  \n",
       "aaaahhhhh            0      0  \n",
       "aaah                 0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix (TDM),\n",
    "# which is the transpose of the DTM\n",
    "tdm = \n",
    "\n",
    "\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format:\n",
    "# from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = \n",
    "\n",
    "corpus = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and \n",
    "# their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_no_stop.pkl\", \"rb\"))\n",
    "\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3674: 'ladies',\n",
       " 2747: 'gentlemen',\n",
       " 7236: 'welcome',\n",
       " 6263: 'stage',\n",
       " 157: 'ali',\n",
       " 7343: 'wong',\n",
       " 3089: 'hi',\n",
       " 3069: 'hello',\n",
       " 6652: 'thank',\n",
       " 1354: 'coming',\n",
       " 4789: 'pee',\n",
       " 4195: 'minutes',\n",
       " 2269: 'everybody',\n",
       " 6962: 'um',\n",
       " 2293: 'exciting',\n",
       " 7409: 'year',\n",
       " 6912: 'turned',\n",
       " 7418: 'yes',\n",
       " 283: 'appreciate',\n",
       " 6958: 'uh',\n",
       " 6608: 'tell',\n",
       " 2761: 'getting',\n",
       " 4558: 'older',\n",
       " 2777: 'girl',\n",
       " 412: 'automatic',\n",
       " 6683: 'thought',\n",
       " 6366: 'straight',\n",
       " 3485: 'jealous',\n",
       " 2595: 'foremost',\n",
       " 4140: 'metabolism',\n",
       " 2780: 'girls',\n",
       " 2100: 'eat',\n",
       " 6012: 'sixpack',\n",
       " 6656: 'thatthat',\n",
       " 551: 'beautiful',\n",
       " 3358: 'inner',\n",
       " 6672: 'thigh',\n",
       " 1244: 'clearance',\n",
       " 2427: 'feet',\n",
       " 3221: 'huge',\n",
       " 2704: 'gap',\n",
       " 3809: 'light',\n",
       " 5025: 'potential',\n",
       " 5254: 'radiating',\n",
       " 6700: 'throughand',\n",
       " 6046: 'sleep',\n",
       " 3371: 'insomnia',\n",
       " 195: 'ambien',\n",
       " 1990: 'download',\n",
       " 4096: 'meditation',\n",
       " 4513: 'oasis',\n",
       " 4952: 'podcast',\n",
       " 949: 'calm',\n",
       " 1119: 'chatter',\n",
       " 5387: 'regret',\n",
       " 5454: 'resentment',\n",
       " 2378: 'family',\n",
       " 1294: 'cluttering',\n",
       " 4177: 'mind',\n",
       " 3842: 'lives',\n",
       " 122: 'ahead',\n",
       " 3216: 'hpv',\n",
       " 4777: 'peace',\n",
       " 4447: 'night',\n",
       " 4555: 'ok',\n",
       " 1338: 'come',\n",
       " 3888: 'loser',\n",
       " 5698: 'says',\n",
       " 3893: 'lot',\n",
       " 4120: 'men',\n",
       " 6986: 'undetectable',\n",
       " 5322: 'really',\n",
       " 2663: 'fucked',\n",
       " 2764: 'ghost',\n",
       " 3366: 'inside',\n",
       " 4122: 'mens',\n",
       " 722: 'bodies',\n",
       " 735: 'boo',\n",
       " 7337: 'womens',\n",
       " 1943: 'doctor',\n",
       " 6756: 'told',\n",
       " 6368: 'strains',\n",
       " 3625: 'kind',\n",
       " 6911: 'turn',\n",
       " 1070: 'cervical',\n",
       " 966: 'cancer',\n",
       " 723: 'body',\n",
       " 3038: 'heal',\n",
       " 3075: 'helpful',\n",
       " 518: 'basically',\n",
       " 1850: 'die',\n",
       " 5056: 'presence',\n",
       " 7332: 'wolverine',\n",
       " 655: 'bitches',\n",
       " 3628: 'kindle',\n",
       " 6913: 'turning',\n",
       " 5803: 'selfhelp',\n",
       " 3795: 'library',\n",
       " 3396: 'interested',\n",
       " 740: 'books',\n",
       " 5859: 'shades',\n",
       " 2881: 'grey',\n",
       " 3803: 'lifechanging',\n",
       " 3953: 'magic',\n",
       " 6715: 'tidying',\n",
       " 1740: 'declutter',\n",
       " 3146: 'home',\n",
       " 42: 'achieve',\n",
       " 4607: 'optimum',\n",
       " 3779: 'level',\n",
       " 6440: 'success',\n",
       " 3186: 'horrible',\n",
       " 4827: 'person',\n",
       " 2992: 'happy',\n",
       " 3073: 'help',\n",
       " 6770: 'tony',\n",
       " 5546: 'robbins',\n",
       " 4103: 'mei',\n",
       " 3130: 'hoarding',\n",
       " 5098: 'problem',\n",
       " 3177: 'hoping',\n",
       " 1058: 'center',\n",
       " 5099: 'problems',\n",
       " 2810: 'goes',\n",
       " 429: 'away',\n",
       " 1886: 'disappear',\n",
       " 4245: 'mom',\n",
       " 7365: 'world',\n",
       " 1523: 'country',\n",
       " 6580: 'taught',\n",
       " 6701: 'throw',\n",
       " 1845: 'dictators',\n",
       " 4657: 'overtake',\n",
       " 6106: 'snatch',\n",
       " 7207: 'wealth',\n",
       " 602: 'better',\n",
       " 3133: 'hold',\n",
       " 5477: 'retainer',\n",
       " 2840: 'grade',\n",
       " 2974: 'handy',\n",
       " 5937: 'shovel',\n",
       " 913: 'busy',\n",
       " 6423: 'stuffing',\n",
       " 2811: 'gold',\n",
       " 915: 'butt',\n",
       " 5619: 'running',\n",
       " 1369: 'communiststhe',\n",
       " 5656: 'san',\n",
       " 2624: 'francisco',\n",
       " 6894: 'trying',\n",
       " 5512: 'rid',\n",
       " 7373: 'worst',\n",
       " 2322: 'experience',\n",
       " 3802: 'life',\n",
       " 2181: 'emotional',\n",
       " 5741: 'screaming',\n",
       " 2463: 'fighting',\n",
       " 7414: 'yelling',\n",
       " 954: 'came',\n",
       " 1255: 'climax',\n",
       " 5378: 'refused',\n",
       " 3773: 'let',\n",
       " 6647: 'texas',\n",
       " 3385: 'instruments',\n",
       " 4000: 'manual',\n",
       " 940: 'calculator',\n",
       " 5097: 'probably',\n",
       " 486: 'bamboozled',\n",
       " 2734: 'generation',\n",
       " 5448: 'required',\n",
       " 922: 'buy',\n",
       " 1509: 'cost',\n",
       " 3553: 'judy',\n",
       " 3509: 'jetsons',\n",
       " 3695: 'laptop',\n",
       " 2690: 'future',\n",
       " 2864: 'graph',\n",
       " 6633: 'tesla',\n",
       " 4399: 'need',\n",
       " 1239: 'clean',\n",
       " 5104: 'procrastinator',\n",
       " 258: 'anymore',\n",
       " 36: 'according',\n",
       " 1745: 'deepakoprah',\n",
       " 7203: 'way',\n",
       " 2880: 'grew',\n",
       " 4751: 'past',\n",
       " 4021: 'married',\n",
       " 3980: 'man',\n",
       " 3917: 'lucky',\n",
       " 2921: 'guy',\n",
       " 2721: 'gave',\n",
       " 2598: 'forever',\n",
       " 1693: 'dated',\n",
       " 3889: 'losers',\n",
       " 3894: 'lots',\n",
       " 6018: 'skaters',\n",
       " 7171: 'wanna',\n",
       " 2896: 'grownass',\n",
       " 7333: 'woman',\n",
       " 6355: 'stop',\n",
       " 1696: 'dating',\n",
       " 7001: 'unless',\n",
       " 7156: 'wake',\n",
       " 4061: 'mattress',\n",
       " 3638: 'kitchen',\n",
       " 5855: 'sexy',\n",
       " 4641: 'outside',\n",
       " 3977: 'malt',\n",
       " 3828: 'liquor',\n",
       " 3244: 'husband',\n",
       " 4139: 'met',\n",
       " 7219: 'wedding',\n",
       " 3877: 'looking',\n",
       " 3737: 'league',\n",
       " 5692: 'saw',\n",
       " 2805: 'god',\n",
       " 3742: 'learned',\n",
       " 388: 'attending',\n",
       " 3008: 'harvard',\n",
       " 910: 'business',\n",
       " 5716: 'school',\n",
       " 6834: 'trap',\n",
       " 347: 'ass',\n",
       " 6835: 'trapped',\n",
       " 3354: 'initially',\n",
       " 3637: 'kissing',\n",
       " 2457: 'fifth',\n",
       " 1692: 'date',\n",
       " 7016: 'unusual',\n",
       " 1848: 'did',\n",
       " 5188: 'purpose',\n",
       " 3647: 'knew',\n",
       " 1029: 'catch',\n",
       " 2829: 'gotta',\n",
       " 3969: 'make',\n",
       " 2056: 'dude',\n",
       " 576: 'believe',\n",
       " 5772: 'secret',\n",
       " 2707: 'garden',\n",
       " 5163: 'public',\n",
       " 4720: 'park',\n",
       " 3197: 'hosted',\n",
       " 5383: 'reggae',\n",
       " 2444: 'fests',\n",
       " 33: 'accidentally',\n",
       " 3148: 'homeless',\n",
       " 3116: 'hipsters',\n",
       " 6360: 'store',\n",
       " 7032: 'urban',\n",
       " 4636: 'outfitters',\n",
       " 6674: 'things',\n",
       " 1425: 'confusing',\n",
       " 3115: 'hipster',\n",
       " 542: 'beard',\n",
       " 2397: 'fashion',\n",
       " 7179: 'warmth',\n",
       " 2985: 'happened',\n",
       " 3845: 'living',\n",
       " 832: 'broad',\n",
       " 1707: 'daylight',\n",
       " 1143: 'chemistry',\n",
       " 3087: 'hey',\n",
       " 7191: 'wassup',\n",
       " 7136: 'volvo',\n",
       " 2034: 'drop',\n",
       " 2035: 'dropped',\n",
       " 2812: 'golden',\n",
       " 2717: 'gate',\n",
       " 7195: 'watched',\n",
       " 5616: 'run',\n",
       " 4160: 'middle',\n",
       " 2650: 'friends',\n",
       " 336: 'asian',\n",
       " 5911: 'shocked',\n",
       " 7047: 'usually',\n",
       " 337: 'asianamerican',\n",
       " 7336: 'women',\n",
       " 7210: 'wear',\n",
       " 3626: 'kinda',\n",
       " 2791: 'glasses',\n",
       " 4602: 'opinions',\n",
       " 7272: 'white',\n",
       " 2057: 'dudes',\n",
       " 4408: 'neighborhood',\n",
       " 3967: 'major',\n",
       " 1216: 'city',\n",
       " 197: 'america',\n",
       " 7425: 'yoko',\n",
       " 4586: 'ono',\n",
       " 2356: 'factory',\n",
       " 7253: 'whats',\n",
       " 7394: 'wrong',\n",
       " 2423: 'feel',\n",
       " 4880: 'picturesque',\n",
       " 7241: 'wes',\n",
       " 215: 'anderson',\n",
       " 4304: 'movie',\n",
       " 6587: 'teach',\n",
       " 1482: 'cool',\n",
       " 6421: 'stuff',\n",
       " 7139: 'voting',\n",
       " 5355: 'recycling',\n",
       " 1932: 'disturbing',\n",
       " 1946: 'documentaries',\n",
       " 3408: 'introduce',\n",
       " 3198: 'hot',\n",
       " 3169: 'hookin',\n",
       " 4080: 'mean',\n",
       " 3971: 'makes',\n",
       " 5035: 'powerful',\n",
       " 2103: 'eats',\n",
       " 5201: 'pussy',\n",
       " 19: 'absorbing',\n",
       " 5094: 'privilege',\n",
       " 2224: 'entitlement',\n",
       " 4252: 'money',\n",
       " 3136: 'hole',\n",
       " 7142: 'vulnerable',\n",
       " 1609: 'crush',\n",
       " 3027: 'head',\n",
       " 4246: 'moment',\n",
       " 3617: 'kill',\n",
       " 789: 'brains',\n",
       " 1330: 'colonize',\n",
       " 1331: 'colonizer',\n",
       " 3654: 'knowbut',\n",
       " 4019: 'marriage',\n",
       " 4439: 'nice',\n",
       " 6142: 'somebody',\n",
       " 5247: 'race',\n",
       " 85: 'advantage',\n",
       " 5253: 'racist',\n",
       " 2330: 'explain',\n",
       " 2943: 'halffilipino',\n",
       " 2945: 'halfjapanese',\n",
       " 2941: 'halfchinese',\n",
       " 2948: 'halfvietnamese',\n",
       " 6201: 'spend',\n",
       " 4816: 'percent',\n",
       " 5906: 'shitting',\n",
       " 3661: 'korean',\n",
       " 193: 'amazing',\n",
       " 3903: 'love',\n",
       " 870: 'built',\n",
       " 3657: 'knowmy',\n",
       " 778: 'boyfriend',\n",
       " 1615: 'cuban',\n",
       " 4150: 'mexican',\n",
       " 2922: 'guys',\n",
       " 300: 'arent',\n",
       " 6980: 'underrated',\n",
       " 5849: 'sexiest',\n",
       " 2933: 'hair',\n",
       " 4397: 'neck',\n",
       " 3973: 'making',\n",
       " 1960: 'dolphin',\n",
       " 6098: 'smooth',\n",
       " 6062: 'slip',\n",
       " 6053: 'slide',\n",
       " 665: 'black',\n",
       " 2502: 'fish',\n",
       " 6722: 'tilikum',\n",
       " 554: 'bed',\n",
       " 4591: 'oohwee',\n",
       " 4133: 'mess',\n",
       " 3511: 'jewish',\n",
       " 5356: 'red',\n",
       " 3343: 'inflamed',\n",
       " 340: 'ask',\n",
       " 2302: 'exfoliated',\n",
       " 6749: 'today',\n",
       " 3484: 'jdate',\n",
       " 3874: 'loofah',\n",
       " 6653: 'thanks',\n",
       " 5606: 'rug',\n",
       " 899: 'burn',\n",
       " 421: 'avi',\n",
       " 4537: 'odor',\n",
       " 6084: 'smell',\n",
       " 5470: 'responsibility',\n",
       " 6963: 'umami',\n",
       " 2531: 'flavor',\n",
       " 1347: 'comes',\n",
       " 2659: 'fromi',\n",
       " 7014: 'unspoken',\n",
       " 6982: 'understanding',\n",
       " 2942: 'halffancy',\n",
       " 2946: 'halfjungle',\n",
       " 1855: 'difference',\n",
       " 2384: 'fancy',\n",
       " 338: 'asians',\n",
       " 1172: 'chinese',\n",
       " 3477: 'japanese',\n",
       " 3196: 'host',\n",
       " 4567: 'olympics',\n",
       " 3565: 'jungle',\n",
       " 1905: 'diseases',\n",
       " 1857: 'different',\n",
       " 2096: 'east',\n",
       " 1298: 'coast',\n",
       " 5093: 'private',\n",
       " 4936: 'playing',\n",
       " 3672: 'lacrosse',\n",
       " 3743: 'learning',\n",
       " 3708: 'latin',\n",
       " 1148: 'chess',\n",
       " 5607: 'rugby',\n",
       " 2468: 'filipino',\n",
       " 1002: 'carlton',\n",
       " 1849: 'didnt',\n",
       " 7108: 'vietnamese',\n",
       " 1695: 'dates',\n",
       " 6771: 'took',\n",
       " 5473: 'restaurant',\n",
       " 7242: 'west',\n",
       " 3886: 'los',\n",
       " 222: 'angeles',\n",
       " 945: 'called',\n",
       " 4854: 'pho',\n",
       " 409: 'authentic',\n",
       " 5307: 'read',\n",
       " 7416: 'yelp',\n",
       " 4499: 'number',\n",
       " 5770: 'second',\n",
       " 525: 'bathroom',\n",
       " 3761: 'legit',\n",
       " 1981: 'double',\n",
       " 6481: 'supply',\n",
       " 1275: 'closet',\n",
       " 2694: 'gallons',\n",
       " 676: 'bleach',\n",
       " 374: 'atm',\n",
       " 3939: 'machine',\n",
       " 2854: 'grandma',\n",
       " 2792: 'glaucoma',\n",
       " 4370: 'napping',\n",
       " 1494: 'corner',\n",
       " 7151: 'wait',\n",
       " 6262: 'staff',\n",
       " 3745: 'leave',\n",
       " 1715: 'deaf',\n",
       " 2182: 'emotionally',\n",
       " 22: 'abused',\n",
       " 6781: 'total',\n",
       " 617: 'big',\n",
       " 3113: 'hippies',\n",
       " 454: 'backpack',\n",
       " 6173: 'southeast',\n",
       " 335: 'asia',\n",
       " 7422: 'yoga',\n",
       " 437: 'ayahuasca',\n",
       " 1066: 'ceremonies',\n",
       " 5977: 'silent',\n",
       " 5482: 'retreats',\n",
       " 4773: 'pay',\n",
       " 5951: 'shut',\n",
       " 7225: 'weekend',\n",
       " 2801: 'glutenfree',\n",
       " 4084: 'means',\n",
       " 800: 'bread',\n",
       " 6576: 'tastes',\n",
       " 2637: 'freerange',\n",
       " 1152: 'chewbacca',\n",
       " 3769: 'lesbian',\n",
       " 6685: 'thousand',\n",
       " 1662: 'daily',\n",
       " 2450: 'fiber',\n",
       " 6226: 'spoken',\n",
       " 7349: 'word',\n",
       " 4956: 'poetry',\n",
       " 5219: 'queef',\n",
       " 5907: 'shitty',\n",
       " 4954: 'poem',\n",
       " 6483: 'supporting',\n",
       " 933: 'caitlyn',\n",
       " 3494: 'jenner',\n",
       " 2687: 'funny',\n",
       " 3114: 'hippydippy',\n",
       " 1955: 'doing',\n",
       " 3304: 'impression',\n",
       " 5749: 'scrolls',\n",
       " 7162: 'wall',\n",
       " 860: 'buddha',\n",
       " 4888: 'piggy',\n",
       " 495: 'bank',\n",
       " 4884: 'pier',\n",
       " 3300: 'imports',\n",
       " 5151: 'providing',\n",
       " 2439: 'feng',\n",
       " 5949: 'shui',\n",
       " 3203: 'house',\n",
       " 7410: 'years',\n",
       " 6110: 'sneaking',\n",
       " 6504: 'suspicion',\n",
       " 5137: 'propose',\n",
       " 5066: 'pressuring',\n",
       " 7144: 'wacky',\n",
       " 3414: 'intuition',\n",
       " 5136: 'proposals',\n",
       " 7353: 'work',\n",
       " 3313: 'incept',\n",
       " 3260: 'idea',\n",
       " 3997: 'mans',\n",
       " 4749: 'passively',\n",
       " 1950: 'doesnt',\n",
       " 4134: 'message',\n",
       " 2342: 'extremely',\n",
       " 114: 'aggressively',\n",
       " 6688: 'threaten',\n",
       " 60: 'actually',\n",
       " 3747: 'leaving',\n",
       " 4557: 'old',\n",
       " 3703: 'late',\n",
       " 4430: 'new',\n",
       " 6286: 'start',\n",
       " 3993: 'manipulation',\n",
       " 1653: 'cycle',\n",
       " 6335: 'stick',\n",
       " 2569: 'focus',\n",
       " 6836: 'trapping',\n",
       " 4355: 'nag',\n",
       " 4645: 'outta',\n",
       " 7205: 'weak',\n",
       " 1047: 'caves',\n",
       " 2759: 'gets',\n",
       " 2419: 'fed',\n",
       " 2482: 'fine',\n",
       " 4023: 'marry',\n",
       " 5138: 'proposed',\n",
       " 3875: 'look',\n",
       " 2283: 'exact',\n",
       " 5530: 'ring',\n",
       " 7172: 'wanted',\n",
       " 4065: 'maybe',\n",
       " 4900: 'pinterest',\n",
       " 4679: 'page',\n",
       " 5822: 'sent',\n",
       " 595: 'best',\n",
       " 2647: 'friend',\n",
       " 5812: 'send',\n",
       " 4901: 'pinterested',\n",
       " 2205: 'engaged',\n",
       " 5679: 'saturday',\n",
       " 762: 'bought',\n",
       " 2013: 'dress',\n",
       " 2578: 'following',\n",
       " 6904: 'tuesday',\n",
       " 6865: 'tried',\n",
       " 5311: 'ready',\n",
       " 5535: 'ripe',\n",
       " 5587: 'rotten',\n",
       " 489: 'banana',\n",
       " 6496: 'surprised',\n",
       " 4550: 'offstage',\n",
       " 1386: 'completely',\n",
       " 5345: 'recognize',\n",
       " 4830: 'personality',\n",
       " 6131: 'soft',\n",
       " 4506: 'nurturing',\n",
       " 1962: 'domestic',\n",
       " 7244: 'weve',\n",
       " 3458: 'ive',\n",
       " 4672: 'packed',\n",
       " 3922: 'lunch',\n",
       " 5997: 'single',\n",
       " 3058: 'hed',\n",
       " 1789: 'dependent',\n",
       " 2842: 'graduated',\n",
       " 2421: 'feed',\n",
       " 2818: 'goodness',\n",
       " 3047: 'heart',\n",
       " 3420: 'investment',\n",
       " 2478: 'financial',\n",
       " 5309: 'reading',\n",
       " 738: 'book',\n",
       " 5894: 'sheryl',\n",
       " 5659: 'sandberg',\n",
       " 5895: 'shes',\n",
       " 1478: 'coo',\n",
       " 2351: 'facebook',\n",
       " 7397: 'wrote',\n",
       " 5528: 'riled',\n",
       " 994: 'careers',\n",
       " 6560: 'talking',\n",
       " 1078: 'challenge',\n",
       " 6005: 'sit',\n",
       " 6545: 'table',\n",
       " 5538: 'rise',\n",
       " 3738: 'lean',\n",
       " 3799: 'lie',\n",
       " 2435: 'feminism',\n",
       " 3519: 'job',\n",
       " 7038: 'used',\n",
       " 6079: 'smart',\n",
       " 1459: 'continue',\n",
       " 2062: 'dumb',\n",
       " 1060: 'century',\n",
       " 2907: 'guess',\n",
       " 6307: 'stay',\n",
       " 6100: 'snacks',\n",
       " 7194: 'watch',\n",
       " 2159: 'ellen',\n",
       " 6426: 'stupid',\n",
       " 5312: 'real',\n",
       " 653: 'bitch',\n",
       " 5609: 'ruined',\n",
       " 2315: 'expected',\n",
       " 3043: 'hear',\n",
       " 4863: 'phrase',\n",
       " 1982: 'doubleincome',\n",
       " 3205: 'household',\n",
       " 7026: 'upset',\n",
       " 1362: 'comments',\n",
       " 4609: 'options',\n",
       " 2634: 'free',\n",
       " 7013: 'unscheduled',\n",
       " 7015: 'unsupervised',\n",
       " 3299: 'importantly',\n",
       " 6227: 'sponsored',\n",
       " 5905: 'shittier',\n",
       " 2581: 'food',\n",
       " 2085: 'earn',\n",
       " 3447: 'ita',\n",
       " 7158: 'walk',\n",
       " 6670: 'theyll',\n",
       " 3552: 'judgmental',\n",
       " 3208: 'housewives',\n",
       " 6377: 'street',\n",
       " 3207: 'housewife',\n",
       " 7160: 'walking',\n",
       " 4037: 'massages',\n",
       " 3921: 'lululemon',\n",
       " 4704: 'pants',\n",
       " 2742: 'genius',\n",
       " 5480: 'retiredi',\n",
       " 7390: 'write',\n",
       " 2642: 'fresh',\n",
       " 713: 'boat',\n",
       " 6: 'abc',\n",
       " 2871: 'great',\n",
       " 1545: 'coworkers',\n",
       " 7392: 'writing',\n",
       " 6626: 'terms',\n",
       " 3520: 'jobs',\n",
       " 4546: 'office',\n",
       " 6025: 'skin',\n",
       " 5765: 'seat',\n",
       " 7037: 'use',\n",
       " 6754: 'toilet',\n",
       " 4706: 'paper',\n",
       " 1538: 'cover',\n",
       " 6727: 'times',\n",
       " 5636: 'sadass',\n",
       " 4078: 'meal',\n",
       " 4577: 'oneply',\n",
       " 5190: 'purposely',\n",
       " 1859: 'difficult',\n",
       " 5172: 'pull',\n",
       " 6893: 'try',\n",
       " 5296: 'ration',\n",
       " 1368: 'communist',\n",
       " 2126: 'effective',\n",
       " 1761: 'dehydrates',\n",
       " 7315: 'wiping',\n",
       " 1801: 'desert',\n",
       " 3835: 'literally',\n",
       " 6184: 'spat',\n",
       " 1708: 'days',\n",
       " 115: 'ago',\n",
       " 3936: 'macgyver',\n",
       " 443: 'baby',\n",
       " 7313: 'wipe',\n",
       " 4238: 'moisten',\n",
       " 449: 'backfired',\n",
       " 2485: 'fingers',\n",
       " 834: 'broke',\n",
       " 1864: 'digitally',\n",
       " 6338: 'stimulated',\n",
       " 1968: 'doo',\n",
       " 2486: 'finish',\n",
       " 5624: 'rushed',\n",
       " 4712: 'paranoid',\n",
       " 5914: 'shoes',\n",
       " 6979: 'underneath',\n",
       " 6268: 'stall',\n",
       " 1534: 'courtneys',\n",
       " 3832: 'listening',\n",
       " 7153: 'waiting',\n",
       " 6728: 'timing',\n",
       " 3240: 'hurry',\n",
       " 2426: 'feels',\n",
       " 935: 'caked',\n",
       " 3870: 'long',\n",
       " 1683: 'dare',\n",
       " 5736: 'scratch',\n",
       " 6985: 'underwear',\n",
       " 2194: 'end',\n",
       " 3878: 'looks',\n",
       " 2821: 'goonies',\n",
       " 4315: 'muffle',\n",
       " 7371: 'worry',\n",
       " 7084: 'velocity',\n",
       " 6250: 'squeeze',\n",
       " 1131: 'cheeks',\n",
       " 6488: 'sure',\n",
       " 6065: 'slow',\n",
       " 6314: 'steady',\n",
       " 4669: 'pace',\n",
       " 7007: 'unpredictable',\n",
       " 4466: 'noise',\n",
       " 6447: 'suddenly',\n",
       " 2244: 'escapes',\n",
       " 828: 'brings',\n",
       " 1744: 'deep',\n",
       " 5868: 'shame',\n",
       " 695: 'blow',\n",
       " 2105: 'echo',\n",
       " 5493: 'reverberate',\n",
       " 2199: 'ends',\n",
       " 2953: 'hallways',\n",
       " 7197: 'watching',\n",
       " 4425: 'netflix',\n",
       " 3430: 'ipad',\n",
       " 747: 'boring',\n",
       " 5443: 'repressed',\n",
       " 5904: 'shits',\n",
       " 3831: 'listen',\n",
       " 4953: 'podcasts',\n",
       " 4918: 'planet',\n",
       " 7174: 'wantyou',\n",
       " 1928: 'distracting',\n",
       " 3887: 'lose',\n",
       " 5464: 'respect',\n",
       " 3135: 'holds',\n",
       " 6162: 'sort',\n",
       " 1576: 'credence',\n",
       " 3044: 'heard',\n",
       " 4419: 'nerve',\n",
       " 490: 'bananas',\n",
       " 2877: 'green',\n",
       " 479: 'ballet',\n",
       " 2530: 'flats',\n",
       " 2405: 'fatherinlaw',\n",
       " 6007: 'sitdown',\n",
       " 5339: 'recently',\n",
       " 6558: 'talk',\n",
       " 5150: 'provide',\n",
       " 1162: 'children',\n",
       " 5095: 'privileged',\n",
       " 1160: 'childhood',\n",
       " 6609: 'telling',\n",
       " 1470: 'conversation',\n",
       " 6149: 'son',\n",
       " 6981: 'understand',\n",
       " 2086: 'earning',\n",
       " 1185: 'choose',\n",
       " 5472: 'rest',\n",
       " 1193: 'chose',\n",
       " 5123: 'promise',\n",
       " 2084: 'early',\n",
       " 5481: 'retirement',\n",
       " 4085: 'meant',\n",
       " 1854: 'dieting',\n",
       " 2102: 'eating',\n",
       " 2646: 'fried',\n",
       " 1155: 'chicken',\n",
       " 2673: 'fulfilling',\n",
       " 1812: 'destiny',\n",
       " 1210: 'circle',\n",
       " 2347: 'eyelashes',\n",
       " 4310: 'mrs',\n",
       " 4675: 'pacman',\n",
       " 3774: 'lets',\n",
       " 5357: 'redecoratei',\n",
       " 1911: 'disgusting',\n",
       " 4835: 'pervert',\n",
       " 2888: 'gross',\n",
       " 2475: 'filthy',\n",
       " 228: 'animal',\n",
       " 6287: 'started',\n",
       " 5001: 'porn',\n",
       " 7433: 'young',\n",
       " 106: 'age',\n",
       " 2988: 'happens',\n",
       " 7442: 'yyou',\n",
       " 5961: 'sicker',\n",
       " 3281: 'images',\n",
       " 1564: 'crave',\n",
       " 3400: 'internet',\n",
       " 7431: 'youi',\n",
       " 3268: 'idiot',\n",
       " 5317: 'realize',\n",
       " 7238: 'went',\n",
       " 1557: 'craigslist',\n",
       " 5017: 'posted',\n",
       " 6733: 'tiny',\n",
       " 2433: 'female',\n",
       " 5783: 'seeking',\n",
       " 206: 'anal',\n",
       " 1559: 'crash',\n",
       " 3974: 'male',\n",
       " 3034: 'heads',\n",
       " 6999: 'universe',\n",
       " 5992: 'simultaneously',\n",
       " 2334: 'explode',\n",
       " 2628: 'freaked',\n",
       " 5705: 'scared',\n",
       " 4683: 'pain',\n",
       " 131: 'aint',\n",
       " 7202: 'wax',\n",
       " 2346: 'eyebrows',\n",
       " 6164: 'sorts',\n",
       " 1569: 'crazy',\n",
       " 1840: 'dick',\n",
       " 2275: 'evil',\n",
       " 5775: 'secrets',\n",
       " 3801: 'lies',\n",
       " 5827: 'sephora',\n",
       " 5203: 'puts',\n",
       " 6676: 'thinking',\n",
       " 1657: 'dad',\n",
       " 1699: 'dave',\n",
       " 2267: 'eventually',\n",
       " 1090: 'change',\n",
       " 1122: 'cheat',\n",
       " 3397: 'interesting',\n",
       " 3137: 'holes',\n",
       " 7432: 'youll',\n",
       " 5854: 'sexually',\n",
       " 54: 'active',\n",
       " 5474: 'result',\n",
       " 3836: 'little',\n",
       " 652: 'bit',\n",
       " 6384: 'stretched',\n",
       " 2477: 'finally',\n",
       " 2432: 'felt',\n",
       " 1087: 'chance',\n",
       " 3954: 'magical',\n",
       " 2390: 'fantasy',\n",
       " 5014: 'possible',\n",
       " 1895: 'discover',\n",
       " 5140: 'prostate',\n",
       " 1433: 'conqueror',\n",
       " 3021: 'havent',\n",
       " 6847: 'treat',\n",
       " 6769: 'tonight',\n",
       " 3838: 'live',\n",
       " 7427: 'yolo',\n",
       " 6107: 'sneak',\n",
       " 5199: 'pushpush',\n",
       " 6917: 'tushtush',\n",
       " 364: 'atari',\n",
       " 5459: 'resistance',\n",
       " 6253: 'squirmy',\n",
       " 7368: 'wormy',\n",
       " 6708: 'thumb',\n",
       " 6439: 'succeed',\n",
       " 2723: 'gay',\n",
       " 2412: 'fear',\n",
       " 6915: 'turns',\n",
       " 2248: 'especially',\n",
       " 4143: 'metamorphosizes',\n",
       " 4938: 'pleasure',\n",
       " 2344: 'eye',\n",
       " 1896: 'discovered',\n",
       " 4459: 'nirvana',\n",
       " 3675: 'lady',\n",
       " 1266: 'clit',\n",
       " 2349: 'eyes',\n",
       " 3884: 'lord',\n",
       " 5529: 'rim',\n",
       " 6989: 'unfortunately',\n",
       " 2632: 'freaky',\n",
       " 341: 'asked',\n",
       " 6182: 'spank',\n",
       " 1949: 'does',\n",
       " 21: 'abuse',\n",
       " 6405: 'strongheaded',\n",
       " 3899: 'loudmouthed',\n",
       " 1062: 'ceos',\n",
       " 5590: 'roughed',\n",
       " 7173: 'wants',\n",
       " 1465: 'control',\n",
       " 5540: 'risk',\n",
       " 1180: 'choke',\n",
       " 6736: 'tired',\n",
       " 750: 'boss',\n",
       " 556: 'bedroom',\n",
       " 4283: 'motherfucker',\n",
       " 3291: 'impact',\n",
       " 487: 'ban',\n",
       " 752: 'bossy',\n",
       " 2152: 'elementary',\n",
       " 5718: 'schools',\n",
       " 5851: 'sexist',\n",
       " 780: 'boys',\n",
       " 3379: 'instead',\n",
       " 5697: 'saying',\n",
       " 6485: 'supposed',\n",
       " 2299: 'executive',\n",
       " 3734: 'leadership',\n",
       " 6024: 'skills',\n",
       " 5592: 'roundabout',\n",
       " 1626: 'cunt',\n",
       " 2479: 'financially',\n",
       " 1068: 'certain',\n",
       " 4958: 'point',\n",
       " 1526: 'couple',\n",
       " 1349: 'comfortably',\n",
       " 94: 'afford',\n",
       " 6050: 'sliced',\n",
       " 3986: 'mango',\n",
       " 2582: 'foods',\n",
       " 3320: 'income',\n",
       " 785: 'bracket',\n",
       " 6397: 'striving',\n",
       " 7439: 'youve',\n",
       " 4363: 'named',\n",
       " 4461: 'noah',\n",
       " 5332: 'rebecca',\n",
       " 3641: 'kiwi',\n",
       " 1680: 'danielle',\n",
       " 4897: 'pineapple',\n",
       " 10: 'able',\n",
       " 6401: 'stroll',\n",
       " 5965: 'sidewalk',\n",
       " 5217: 'quarter',\n",
       " 5082: 'princess',\n",
       " 7039: 'useful',\n",
       " 88: 'advice',\n",
       " 841: 'brothers',\n",
       " 6004: 'sisters',\n",
       " 4686: 'paintballing',\n",
       " 7107: 'vietnam',\n",
       " 7092: 'veteran',\n",
       " 5840: 'seven',\n",
       " 2939: 'half',\n",
       " 4264: 'months',\n",
       " 5050: 'pregnant',\n",
       " 5292: 'rare',\n",
       " 1351: 'comic',\n",
       " 4819: 'perform',\n",
       " 1352: 'comics',\n",
       " 2733: 'generally',\n",
       " 1017: 'case',\n",
       " 7224: 'week',\n",
       " 444: 'babys',\n",
       " 4881: 'piece',\n",
       " 240: 'annoying',\n",
       " 1661: 'dads',\n",
       " 398: 'audience',\n",
       " 3100: 'hilarious',\n",
       " 3266: 'identify',\n",
       " 2375: 'fame',\n",
       " 6523: 'swells',\n",
       " 5396: 'relatable',\n",
       " 6446: 'sudden',\n",
       " 1102: 'chapping',\n",
       " 4457: 'nipples',\n",
       " 2422: 'feeding',\n",
       " 7211: 'wearing',\n",
       " 2660: 'frozen',\n",
       " 1836: 'diaper',\n",
       " 4402: 'needs',\n",
       " 5944: 'shredding',\n",
       " 2984: 'happen',\n",
       " 6274: 'standup',\n",
       " 6441: 'successful',\n",
       " 2382: 'famous',\n",
       " 1893: 'discouraged',\n",
       " 3022: 'having',\n",
       " 3613: 'kid',\n",
       " 3680: 'lame',\n",
       " 6308: 'stayathome',\n",
       " 2009: 'dream',\n",
       " 6961: 'ultimate',\n",
       " 7338: 'won',\n",
       " 3653: 'knowanother',\n",
       " 1894: 'discouraging',\n",
       " 6840: 'travel',\n",
       " 380: 'attached',\n",
       " 1853: 'dies',\n",
       " 1755: 'definitely',\n",
       " 2903: 'guaranteed',\n",
       " 634: 'billion',\n",
       " 6916: 'turtle',\n",
       " 2693: 'galapagos',\n",
       " 1550: 'crack',\n",
       " 464: 'bad',\n",
       " 2027: 'drivers',\n",
       " 3421: 'invincible',\n",
       " 3286: 'imma',\n",
       " 3751: 'left',\n",
       " 2960: 'hand',\n",
       " 5967: 'signal',\n",
       " 3271: 'ignore',\n",
       " 1091: 'changed',\n",
       " 7050: 'uturn',\n",
       " 4633: 'oturn',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show id2word\n",
    "id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the term-document matrix and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"dad\" + 0.005*\"love\" + 0.004*\"little\" + 0.004*\"did\" + 0.004*\"man\" + 0.004*\"life\" + 0.004*\"guys\" + 0.004*\"really\" + 0.004*\"way\" + 0.004*\"shes\"'),\n",
       " (1,\n",
       "  '0.006*\"didnt\" + 0.005*\"went\" + 0.004*\"really\" + 0.004*\"come\" + 0.004*\"goes\" + 0.004*\"little\" + 0.004*\"life\" + 0.004*\"guy\" + 0.004*\"did\" + 0.004*\"id\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the term-document matrix and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = \n",
    "\n",
    "\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"went\" + 0.000*\"man\" + 0.000*\"didnt\" + 0.000*\"make\" + 0.000*\"life\" + 0.000*\"love\" + 0.000*\"goes\" + 0.000*\"way\" + 0.000*\"little\" + 0.000*\"come\"'),\n",
       " (1,\n",
       "  '0.006*\"didnt\" + 0.006*\"went\" + 0.005*\"man\" + 0.005*\"goes\" + 0.005*\"come\" + 0.004*\"really\" + 0.004*\"little\" + 0.004*\"guy\" + 0.004*\"id\" + 0.004*\"did\"'),\n",
       " (2,\n",
       "  '0.005*\"love\" + 0.005*\"life\" + 0.005*\"dad\" + 0.004*\"really\" + 0.004*\"did\" + 0.004*\"little\" + 0.004*\"guys\" + 0.004*\"way\" + 0.004*\"shes\" + 0.004*\"hey\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = \n",
    "\n",
    "\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"joke\" + 0.006*\"anthony\" + 0.005*\"guys\" + 0.005*\"tell\" + 0.004*\"grandma\" + 0.004*\"did\" + 0.004*\"school\" + 0.004*\"jokes\" + 0.004*\"ive\" + 0.004*\"okay\"'),\n",
       " (1,\n",
       "  '0.009*\"went\" + 0.007*\"didnt\" + 0.005*\"ive\" + 0.005*\"man\" + 0.005*\"goes\" + 0.005*\"little\" + 0.005*\"come\" + 0.004*\"id\" + 0.004*\"really\" + 0.004*\"did\"'),\n",
       " (2,\n",
       "  '0.005*\"really\" + 0.005*\"life\" + 0.005*\"little\" + 0.004*\"didnt\" + 0.004*\"way\" + 0.004*\"man\" + 0.004*\"did\" + 0.004*\"love\" + 0.004*\"guy\" + 0.004*\"make\"'),\n",
       " (3,\n",
       "  '0.010*\"dad\" + 0.006*\"love\" + 0.006*\"shes\" + 0.005*\"hasan\" + 0.004*\"life\" + 0.004*\"mom\" + 0.004*\"hey\" + 0.004*\"did\" + 0.004*\"look\" + 0.004*\"brown\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = \n",
    "\n",
    "\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lip/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download punkt and perceptron tagger as lookup\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize, pos_tag #part to speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DS420', 'NNP'),\n",
       " ('class', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('fun', 'NN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example function calls\n",
    "pos_tag(word_tokenize(\"DS420 class has so much fun\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def get_all_nouns(text):\n",
    "    '''\n",
    "    Given a string of text, tokenize the text,\n",
    "    and pull out only the nouns.\n",
    "    '''\n",
    "    # Write a lambda expression to check with tag\n",
    "    # return True if the tag starts with 'NN'\n",
    "    is_noun = \n",
    "    \n",
    "    \n",
    "    # Tokenize the input string text\n",
    "    tokenized = \n",
    "    \n",
    "    \n",
    "    # Use a for loop or list comprehension to generate a list\n",
    "    # of all nouns from the vectorized text\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return a new string with all nouns\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies and gentlemen please welcome to the sta...</td>\n",
       "      <td>Ali Wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank you thank you thank you san francisco th...</td>\n",
       "      <td>Anthony Jeselnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>all right thank you thank you very much thank...</td>\n",
       "      <td>Bill Burr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>bo what old macdonald had a farm e i e i o and...</td>\n",
       "      <td>Bo Burnham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>this is dave he tells dirty jokes for a living...</td>\n",
       "      <td>Dave Chappelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats up davis whats up im home i had to bri...</td>\n",
       "      <td>Hasan Minhaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies and gentlemen please welcome to the ...</td>\n",
       "      <td>Jim Jefferies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies and gentlemen welcome joe rogan  wha...</td>\n",
       "      <td>Joe Rogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>all right petunia wish me luck out there you w...</td>\n",
       "      <td>John Mulaney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>introfade the music out lets roll hold there l...</td>\n",
       "      <td>Louis C.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thank you thanks thank you guys hey se...</td>\n",
       "      <td>Mike Birbiglia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello hello how you doing great thank you wow ...</td>\n",
       "      <td>Ricky Gervais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript         full_name\n",
       "ali      ladies and gentlemen please welcome to the sta...          Ali Wong\n",
       "anthony  thank you thank you thank you san francisco th...  Anthony Jeselnik\n",
       "bill      all right thank you thank you very much thank...         Bill Burr\n",
       "bo       bo what old macdonald had a farm e i e i o and...        Bo Burnham\n",
       "dave     this is dave he tells dirty jokes for a living...    Dave Chappelle\n",
       "hasan      whats up davis whats up im home i had to bri...      Hasan Minhaj\n",
       "jim         ladies and gentlemen please welcome to the ...     Jim Jefferies\n",
       "joe         ladies and gentlemen welcome joe rogan  wha...         Joe Rogan\n",
       "john     all right petunia wish me luck out there you w...      John Mulaney\n",
       "louis    introfade the music out lets roll hold there l...        Louis C.K.\n",
       "mike     wow hey thank you thanks thank you guys hey se...    Mike Birbiglia\n",
       "ricky    hello hello how you doing great thank you wow ...     Ricky Gervais"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies gentlemen stage ali hi thank hello na s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank thank people i em i francisco city world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>thank thank pleasure georgia area oasis i june...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>macdonald farm e i o farm pig e i i snort macd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>jokes living stare work profound train thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats davis whats home i netflix la york i son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies gentlemen stage mr jim jefferies thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies gentlemen joe fuck thanks phone fuckfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>petunia thats hello hello chicago thank crowd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>music lets lights lights thank i i place place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thanks look insane years everyone i id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello thank fuck thank im gon youre weve money...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript\n",
       "ali      ladies gentlemen stage ali hi thank hello na s...\n",
       "anthony  thank thank people i em i francisco city world...\n",
       "bill     thank thank pleasure georgia area oasis i june...\n",
       "bo       macdonald farm e i o farm pig e i i snort macd...\n",
       "dave     jokes living stare work profound train thought...\n",
       "hasan    whats davis whats home i netflix la york i son...\n",
       "jim      ladies gentlemen stage mr jim jefferies thank ...\n",
       "joe      ladies gentlemen joe fuck thanks phone fuckfac...\n",
       "john     petunia thats hello hello chicago thank crowd ...\n",
       "louis    music lets lights lights thank i i place place...\n",
       "mike     wow hey thanks look insane years everyone i id...\n",
       "ricky    hello thank fuck thank im gon youre weve money..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the get_all_nouns function() to the transcripts to filter only on nouns\n",
    "data_nouns = \n",
    "\n",
    "\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>ze</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 4623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aah  abc  abcs  ability  \\\n",
       "ali                 0                 0          0    0    1     0        0   \n",
       "anthony             0                 0          0    0    0     0        0   \n",
       "bill                0                 0          0    0    0     1        0   \n",
       "bo                  1                 1          1    0    0     0        1   \n",
       "dave                0                 0          0    0    0     0        0   \n",
       "hasan               0                 0          0    0    0     0        0   \n",
       "jim                 0                 0          0    0    0     0        0   \n",
       "joe                 0                 0          0    0    0     0        0   \n",
       "john                0                 0          0    0    0     0        0   \n",
       "louis               0                 0          0    3    0     0        0   \n",
       "mike                0                 0          0    0    0     0        0   \n",
       "ricky               0                 0          0    0    0     0        1   \n",
       "\n",
       "         abortion  abortions  abuse  ...  yummy  ze  zealand  zee  zeppelin  \\\n",
       "ali             0          0      0  ...      0   0        0    0         0   \n",
       "anthony         2          0      0  ...      0   0       10    0         0   \n",
       "bill            0          0      0  ...      0   1        0    0         0   \n",
       "bo              0          0      0  ...      0   0        0    0         0   \n",
       "dave            0          1      0  ...      0   0        0    0         0   \n",
       "hasan           0          0      0  ...      0   0        0    1         0   \n",
       "jim             0          0      0  ...      0   0        0    0         0   \n",
       "joe             0          0      1  ...      0   0        0    0         0   \n",
       "john            0          0      0  ...      0   0        0    0         0   \n",
       "louis           0          0      0  ...      0   0        0    0         0   \n",
       "mike            0          0      0  ...      0   0        0    0         2   \n",
       "ricky           0          0      0  ...      1   0        0    0         0   \n",
       "\n",
       "         zillion  zombie  zombies  zoo  éclair  \n",
       "ali            0       1        0    0       0  \n",
       "anthony        0       0        0    0       0  \n",
       "bill           1       1        1    0       0  \n",
       "bo             0       0        0    0       0  \n",
       "dave           0       0        0    0       0  \n",
       "hasan          0       0        0    0       0  \n",
       "jim            0       0        0    0       0  \n",
       "joe            0       0        0    0       0  \n",
       "john           0       0        0    0       1  \n",
       "louis          0       0        0    0       0  \n",
       "mike           0       0        0    0       0  \n",
       "ricky          0       0        0    1       0  \n",
       "\n",
       "[12 rows x 4623 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "\n",
    "# Step1: create a new count vectorizer with the customized stop words\n",
    "cvn = \n",
    "\n",
    "\n",
    "# Step2: transform the data with the cvn\n",
    "data_cvn = \n",
    "\n",
    "\n",
    "# Step3: generate a dataframe\n",
    "data_dtmn = \n",
    "\n",
    "\n",
    "\n",
    "# Show data_dtmn\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus - TDM\n",
    "tdmn = \n",
    "\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"life\" + 0.009*\"man\" + 0.007*\"way\" + 0.007*\"kids\" + 0.006*\"guy\" + 0.006*\"dad\" + 0.006*\"years\" + 0.006*\"gon\" + 0.006*\"shes\" + 0.006*\"things\"'),\n",
       " (1,\n",
       "  '0.006*\"women\" + 0.006*\"lot\" + 0.006*\"man\" + 0.005*\"way\" + 0.005*\"guy\" + 0.005*\"stuff\" + 0.005*\"gon\" + 0.004*\"point\" + 0.004*\"night\" + 0.004*\"life\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = \n",
    "\n",
    "\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"dad\" + 0.008*\"life\" + 0.007*\"way\" + 0.007*\"man\" + 0.007*\"house\" + 0.007*\"shes\" + 0.006*\"mom\" + 0.006*\"joke\" + 0.006*\"kids\" + 0.006*\"things\"'),\n",
       " (1,\n",
       "  '0.006*\"stuff\" + 0.006*\"point\" + 0.006*\"way\" + 0.006*\"lot\" + 0.005*\"kind\" + 0.005*\"gon\" + 0.005*\"bo\" + 0.005*\"man\" + 0.005*\"night\" + 0.005*\"repeat\"'),\n",
       " (2,\n",
       "  '0.010*\"man\" + 0.010*\"guy\" + 0.010*\"life\" + 0.007*\"women\" + 0.007*\"gon\" + 0.007*\"lot\" + 0.006*\"way\" + 0.005*\"kids\" + 0.005*\"woman\" + 0.005*\"dude\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = \n",
    "\n",
    "\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"dad\" + 0.010*\"life\" + 0.009*\"man\" + 0.009*\"house\" + 0.008*\"shes\" + 0.007*\"girl\" + 0.007*\"kids\" + 0.006*\"mom\" + 0.006*\"way\" + 0.005*\"kid\"'),\n",
       " (1,\n",
       "  '0.008*\"stuff\" + 0.007*\"point\" + 0.007*\"way\" + 0.007*\"bo\" + 0.006*\"repeat\" + 0.006*\"kind\" + 0.005*\"night\" + 0.005*\"id\" + 0.005*\"eye\" + 0.005*\"contact\"'),\n",
       " (2,\n",
       "  '0.012*\"life\" + 0.011*\"guy\" + 0.008*\"man\" + 0.008*\"gon\" + 0.007*\"women\" + 0.007*\"kids\" + 0.006*\"way\" + 0.006*\"kid\" + 0.006*\"dude\" + 0.005*\"lot\"'),\n",
       " (3,\n",
       "  '0.008*\"lot\" + 0.007*\"joke\" + 0.007*\"man\" + 0.007*\"way\" + 0.006*\"years\" + 0.006*\"things\" + 0.005*\"women\" + 0.005*\"money\" + 0.005*\"mom\" + 0.005*\"woman\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = \n",
    "\n",
    "\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def get_nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>ladies gentlemen welcome stage ali wong hi wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>thank san francisco thank good people surprise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>right thank thank pleasure greater atlanta geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>old macdonald farm e i i o farm pig e i i snor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>dirty jokes living stare most hard work profou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>whats davis whats im home i netflix special la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>ladies gentlemen welcome stage mr jim jefferie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>ladies gentlemen joe fuck san francisco thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>right petunia august thats good right hello he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>music lets lights lights thank much i i i nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>wow hey thanks hey seattle nice look crazy ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>hello great thank fuck thank lovely welcome im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript\n",
       "ali      ladies gentlemen welcome stage ali wong hi wel...\n",
       "anthony  thank san francisco thank good people surprise...\n",
       "bill     right thank thank pleasure greater atlanta geo...\n",
       "bo       old macdonald farm e i i o farm pig e i i snor...\n",
       "dave     dirty jokes living stare most hard work profou...\n",
       "hasan    whats davis whats im home i netflix special la...\n",
       "jim      ladies gentlemen welcome stage mr jim jefferie...\n",
       "joe      ladies gentlemen joe fuck san francisco thanks...\n",
       "john     right petunia august thats good right hello he...\n",
       "louis    music lets lights lights thank much i i i nice...\n",
       "mike     wow hey thanks hey seattle nice look crazy ins...\n",
       "ricky    hello great thank fuck thank lovely welcome im..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = \n",
    "\n",
    "\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aah</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>ze</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoo</th>\n",
       "      <th>éclair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ali</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bill</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 5535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaaaah  aaaaahhhhhhh  aaaaauuugghhhhhh  aaaahhhhh  aah  abc  abcs  \\\n",
       "ali           0             0                 0          0    0    1     0   \n",
       "anthony       0             0                 0          0    0    0     0   \n",
       "bill          1             0                 0          0    0    0     1   \n",
       "bo            0             1                 1          1    0    0     0   \n",
       "dave          0             0                 0          0    0    0     0   \n",
       "hasan         0             0                 0          0    0    0     0   \n",
       "jim           0             0                 0          0    0    0     0   \n",
       "joe           0             0                 0          0    0    0     0   \n",
       "john          0             0                 0          0    0    0     0   \n",
       "louis         0             0                 0          0    3    0     0   \n",
       "mike          0             0                 0          0    0    0     0   \n",
       "ricky         0             0                 0          0    0    0     0   \n",
       "\n",
       "         ability  abject  able  ...  ze  zealand  zee  zeppelin  zero  \\\n",
       "ali            0       0     2  ...   0        0    0         0     0   \n",
       "anthony        0       0     0  ...   0       10    0         0     0   \n",
       "bill           0       0     1  ...   1        0    0         0     0   \n",
       "bo             1       0     0  ...   0        0    0         0     1   \n",
       "dave           0       0     0  ...   0        0    0         0     0   \n",
       "hasan          0       0     1  ...   0        0    2         0     0   \n",
       "jim            0       0     1  ...   0        0    0         0     0   \n",
       "joe            0       0     2  ...   0        0    0         0     0   \n",
       "john           0       0     3  ...   0        0    0         0     0   \n",
       "louis          0       0     1  ...   0        0    0         0     0   \n",
       "mike           0       0     0  ...   0        0    0         2     0   \n",
       "ricky          1       1     2  ...   0        0    0         0     0   \n",
       "\n",
       "         zillion  zombie  zombies  zoo  éclair  \n",
       "ali            0       1        0    0       0  \n",
       "anthony        0       0        0    0       0  \n",
       "bill           1       1        1    0       0  \n",
       "bo             0       0        0    0       0  \n",
       "dave           0       0        0    0       0  \n",
       "hasan          0       0        0    0       0  \n",
       "jim            0       0        0    0       0  \n",
       "joe            0       0        0    0       0  \n",
       "john           0       0        0    0       1  \n",
       "louis          0       0        0    0       0  \n",
       "mike           0       0        0    0       0  \n",
       "ricky          0       0        0    1       0  \n",
       "\n",
       "[12 rows x 5535 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, \n",
    "# also remove common words with max_df\n",
    "\n",
    "# Step1: create a new count vectorizer with the customized stop words\n",
    "# Set max_df to 70% to remove frequent words.\n",
    "cvna = \n",
    "\n",
    "\n",
    "# Step 2: transform the data with the cvna\n",
    "data_cvna = \n",
    "\n",
    "\n",
    "# Step 3: generate a dataframe\n",
    "data_dtmna = \n",
    "\n",
    "\n",
    "\n",
    "# Show the dataframe\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus - TDM\n",
    "tdmna = \n",
    "\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"joke\" + 0.003*\"gun\" + 0.003*\"bo\" + 0.003*\"class\" + 0.003*\"jenny\" + 0.003*\"gay\" + 0.002*\"repeat\" + 0.002*\"guns\" + 0.002*\"hell\" + 0.002*\"ass\"'),\n",
       " (1,\n",
       "  '0.007*\"mom\" + 0.003*\"joke\" + 0.003*\"ok\" + 0.003*\"hasan\" + 0.003*\"clinton\" + 0.003*\"president\" + 0.002*\"anthony\" + 0.002*\"ass\" + 0.002*\"mad\" + 0.002*\"york\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = \n",
    "\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"joke\" + 0.004*\"bo\" + 0.004*\"jenny\" + 0.003*\"repeat\" + 0.003*\"eye\" + 0.003*\"hell\" + 0.003*\"nuts\" + 0.003*\"sort\" + 0.003*\"contact\" + 0.003*\"andy\"'),\n",
       " (1,\n",
       "  '0.008*\"joke\" + 0.006*\"anthony\" + 0.005*\"husband\" + 0.005*\"mom\" + 0.005*\"grandma\" + 0.005*\"ok\" + 0.004*\"mad\" + 0.004*\"pregnant\" + 0.004*\"shark\" + 0.003*\"san\"'),\n",
       " (2,\n",
       "  '0.005*\"mom\" + 0.003*\"ass\" + 0.003*\"wife\" + 0.003*\"hasan\" + 0.003*\"clinton\" + 0.003*\"president\" + 0.003*\"guns\" + 0.003*\"ahah\" + 0.002*\"class\" + 0.002*\"york\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = \n",
    "\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"jenny\" + 0.005*\"ahah\" + 0.004*\"gay\" + 0.003*\"nigga\" + 0.003*\"wife\" + 0.003*\"gun\" + 0.003*\"accident\" + 0.003*\"trouble\" + 0.003*\"sudden\" + 0.002*\"argument\"'),\n",
       " (1,\n",
       "  '0.008*\"husband\" + 0.007*\"ok\" + 0.006*\"pregnant\" + 0.004*\"asian\" + 0.004*\"fingers\" + 0.004*\"doo\" + 0.004*\"mom\" + 0.004*\"wan\" + 0.004*\"toilet\" + 0.003*\"ass\"'),\n",
       " (2,\n",
       "  '0.008*\"mom\" + 0.004*\"hasan\" + 0.004*\"clinton\" + 0.004*\"president\" + 0.003*\"york\" + 0.003*\"tit\" + 0.003*\"cow\" + 0.003*\"wife\" + 0.003*\"brown\" + 0.003*\"ha\"'),\n",
       " (3,\n",
       "  '0.011*\"joke\" + 0.005*\"bo\" + 0.004*\"guns\" + 0.004*\"repeat\" + 0.004*\"um\" + 0.004*\"anthony\" + 0.003*\"eye\" + 0.003*\"ass\" + 0.003*\"contact\" + 0.003*\"hell\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = \n",
    "\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the topic models we looked at, the nouns and adjectives with 4 topics made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"jenny\" + 0.005*\"ahah\" + 0.004*\"gay\" + 0.003*\"nigga\" + 0.003*\"gun\" + 0.003*\"wife\" + 0.003*\"accident\" + 0.003*\"sudden\" + 0.003*\"trouble\" + 0.002*\"argument\"'),\n",
       " (1,\n",
       "  '0.008*\"husband\" + 0.007*\"ok\" + 0.006*\"pregnant\" + 0.004*\"asian\" + 0.004*\"fingers\" + 0.004*\"doo\" + 0.004*\"toilet\" + 0.004*\"mom\" + 0.004*\"wan\" + 0.003*\"body\"'),\n",
       " (2,\n",
       "  '0.008*\"mom\" + 0.004*\"hasan\" + 0.004*\"clinton\" + 0.004*\"president\" + 0.003*\"york\" + 0.003*\"tit\" + 0.003*\"cow\" + 0.003*\"brown\" + 0.003*\"wife\" + 0.003*\"ha\"'),\n",
       " (3,\n",
       "  '0.011*\"joke\" + 0.005*\"bo\" + 0.004*\"guns\" + 0.004*\"repeat\" + 0.004*\"um\" + 0.004*\"anthony\" + 0.004*\"eye\" + 0.003*\"ass\" + 0.003*\"contact\" + 0.003*\"brain\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = \n",
    "\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four topics look pretty decent. Let's settle on these for now.\n",
    "* Topic 0 - Violence.\n",
    "* Topic 1 - Husband and Wife. \n",
    "* Topic 2 - Mom and Clinton.\n",
    "* Topic 3 - Joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'ali'),\n",
       " (3, 'anthony'),\n",
       " (0, 'bill'),\n",
       " (3, 'bo'),\n",
       " (0, 'dave'),\n",
       " (2, 'hasan'),\n",
       " (3, 'jim'),\n",
       " (2, 'joe'),\n",
       " (2, 'john'),\n",
       " (2, 'louis'),\n",
       " (0, 'mike'),\n",
       " (3, 'ricky')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[tdmna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a first pass of LDA, these kind of make sense to me, so we'll call it a day for now.\n",
    "* Topic 0: Violence [Bill, Dave, Mike]\n",
    "* Topic 1: Husband and Wife [Ali]\n",
    "* Topic 2: Mom and Clinton [Hassan, Joe, John]\n",
    "* Topic 3: Joke [Anthony, Bo, Jim, Ricky]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try further modifying the parameters of the topic models above and see if you can get better topics.\n",
    "2. Create a new topic model that includes terms from a different [part of speech](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and see if you can get better topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
